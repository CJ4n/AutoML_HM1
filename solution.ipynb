{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "- trzeba się zastanowić jakie zakres hyper parametrów bierzemy - ADAM -TODO\n",
    "- sprawdić jak zmiana seed w random search wpływa na wyniki tunowalnośći (sampling bias) - TODO (zmienaimy seed i patrzymy czy tunowalność się zmienia -> tabelka z 10 seedami i patrzyma jak zmienia się tunowalnosć) -TODO ( przy pisaniu raportu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame, Series\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from skopt.space import Integer, Real\n",
    "\n",
    "from utills.best_config_bayes import (\n",
    "    find_best_config_using_bayes,\n",
    "    find_best_configs_in_search_space_with_bayes,\n",
    ")\n",
    "from utills.best_config_random_search import (\n",
    "    find_best_configs_in_search_space_with_random_search,\n",
    ")\n",
    "from utills.dataset import load_dataset_from_id, split_dataset\n",
    "from utills.dump_data import (\n",
    "    dump_optimal_config_search_history,\n",
    "    dump_scores_to_csv,\n",
    "    dump_tunability_to_csv,\n",
    ")\n",
    "from utills.optimal_config import find_optimal_configuration_for_all_datasets\n",
    "from utills.pipeline import get_column_transformer\n",
    "from utills.tunability import (\n",
    "    calculate_aggregate_tunability,\n",
    "    calculate_tunability_on_each_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ITER_BAYES = 50\n",
    "NUM_POINTS_RS_DECISION_TREE = 50\n",
    "NUM_POINTS_RS_ELASTIC_NET = 50\n",
    "NUM_POINTS_RS_RANDOM_FOREST = 50\n",
    "SEED = 321"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utill functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_market_dataset_id = (\n",
    "    43308  # https://www.openml.org/search?type=data&id=43308&sort=runs&status=active\n",
    ")\n",
    "cars_dataset_id = (\n",
    "    44994  # https://www.openml.org/search?type=data&status=active&id=44994\n",
    ")\n",
    "diabetes_dataset_id = (\n",
    "    44223  # https://www.openml.org/search?type=data&id=44223&sort=runs&status=active\n",
    ")\n",
    "\n",
    "lisbona_house_prices_dataset_id = (\n",
    "    43660  # https://www.openml.org/search?type=data&id=43660&sort=runs&status=active\n",
    ")\n",
    "\n",
    "rmftsa_ladata_dataset_id = (\n",
    "    666  # https://www.openml.org/search?type=data&status=active&id=666\n",
    ")\n",
    "boston_dataset_id = 531  # https://www.openml.org/search?type=data&status=active&id=531\n",
    "\n",
    "treasury_dataset_id = (\n",
    "    42367  # https://www.openml.org/search?type=data&status=active&id=42367\n",
    ")\n",
    "\n",
    "bank32nh_dataset_id = (\n",
    "    558  # https://www.openml.org/search?type=data&status=active&id=558\n",
    ")\n",
    "\n",
    "puma32H_dataset_id = 308  # https://www.openml.org/search?type=data&status=active&id=308\n",
    "\n",
    "fish_market_dataset: DataFrame = load_dataset_from_id(id=fish_market_dataset_id)\n",
    "fish_market_regression_class = \"Weight\"\n",
    "\n",
    "cars_dataset: DataFrame = load_dataset_from_id(id=cars_dataset_id)\n",
    "cars_regression_class = \"Price\"\n",
    "\n",
    "diabetes_dataset: DataFrame = load_dataset_from_id(id=diabetes_dataset_id)\n",
    "diabetes_regression_class = \"class\"\n",
    "\n",
    "lisbona_house_prices_dataset: DataFrame = load_dataset_from_id(\n",
    "    id=lisbona_house_prices_dataset_id\n",
    ")\n",
    "lisbona_house_prices_regression_class = \"Price\"\n",
    "\n",
    "rmftsa_ladata_dataset = load_dataset_from_id(id=rmftsa_ladata_dataset_id)\n",
    "rmftsa_ladata_regression_class = \"Respiratory_Mortality\"\n",
    "\n",
    "boston_dataset = load_dataset_from_id(id=boston_dataset_id)\n",
    "boston_regression_class = \"MEDV\"\n",
    "\n",
    "treasury_dataset = load_dataset_from_id(id=treasury_dataset_id)\n",
    "treasury_regression_class = \"1MonthCDRate\"\n",
    "\n",
    "bank32nh_dataset = load_dataset_from_id(id=bank32nh_dataset_id)\n",
    "bank32nh_regression_class = \"rej\"\n",
    "\n",
    "puma32H_dataset = load_dataset_from_id(id=puma32H_dataset_id)\n",
    "puma32H_regression_class = \"thetadd6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_train_fish_market,\n",
    "    X_test_fish_market,\n",
    "    y_train_fish_market,\n",
    "    y_test_fish_market,\n",
    ") = split_dataset(data=fish_market_dataset, class_=fish_market_regression_class)\n",
    "\n",
    "(\n",
    "    X_train_cars,\n",
    "    X_test_cars,\n",
    "    y_train_cars,\n",
    "    y_test_cars,\n",
    ") = split_dataset(data=cars_dataset, class_=cars_regression_class)\n",
    "\n",
    "X_train_diabetes, X_test_diabetes, y_train_diabetes, y_test_diabetes = split_dataset(\n",
    "    diabetes_dataset, diabetes_regression_class\n",
    ")\n",
    "\n",
    "(\n",
    "    X_train_lisbona_house_prices,\n",
    "    X_test_lisbona_house_prices,\n",
    "    y_train_lisbona_house_prices,\n",
    "    y_test_lisbona_house_prices,\n",
    ") = split_dataset(lisbona_house_prices_dataset, lisbona_house_prices_regression_class)\n",
    "\n",
    "(\n",
    "    X_train_rmftsa_ladata,\n",
    "    X_test_rmftsa_ladata,\n",
    "    y_train_rmftsa_ladata,\n",
    "    y_test_rmftsa_ladata,\n",
    ") = split_dataset(rmftsa_ladata_dataset, rmftsa_ladata_regression_class)\n",
    "\n",
    "X_train_boston, X_test_boston, y_train_boston, y_test_boston = split_dataset(\n",
    "    boston_dataset, boston_regression_class\n",
    ")\n",
    "\n",
    "X_train_treasury, X_test_treasury, y_train_treasury, y_test_treasury = split_dataset(\n",
    "    treasury_dataset, treasury_regression_class\n",
    ")\n",
    "\n",
    "X_train_bank32nh, X_test_bank32nh, y_train_bank32nh, y_test_bank32nh = split_dataset(\n",
    "    bank32nh_dataset, bank32nh_regression_class\n",
    ")\n",
    "\n",
    "X_train_puma32H, X_test_puma32H, y_train_puma32H, y_test_puma32H = split_dataset(\n",
    "    puma32H_dataset, puma32H_regression_class\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_datasets() -> List[Tuple[DataFrame, Series]]:\n",
    "    return [\n",
    "        (X_train_fish_market, y_train_fish_market),\n",
    "        (X_train_cars, y_train_cars),\n",
    "        (X_train_diabetes, y_train_diabetes),\n",
    "        (X_train_lisbona_house_prices, y_train_lisbona_house_prices),\n",
    "        (X_train_rmftsa_ladata, y_train_rmftsa_ladata),\n",
    "        (X_train_boston, y_train_boston),\n",
    "        (X_train_treasury, y_train_treasury),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_datasets():\n",
    "    return [\n",
    "        (X_test_fish_market, y_test_fish_market),\n",
    "        (X_test_cars, y_test_cars),\n",
    "        (X_test_diabetes, y_test_diabetes),\n",
    "        (X_test_lisbona_house_prices, y_test_lisbona_house_prices),\n",
    "        (X_test_rmftsa_ladata, y_test_rmftsa_ladata),\n",
    "        (X_test_boston, y_test_boston),\n",
    "        (X_test_treasury, y_test_treasury),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model and search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decision_tree_pipeline() -> Pipeline:\n",
    "    decision_tree = DecisionTreeRegressor(random_state=SEED)\n",
    "    col_trans: ColumnTransformer = get_column_transformer()\n",
    "    decision_tree_pipeline = Pipeline(\n",
    "        steps=[(\"column_transformer\", col_trans), (\"model\", decision_tree)]\n",
    "    )\n",
    "    return decision_tree_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameter_grid_decision_tree():\n",
    "    # parameters space\n",
    "    random.seed(SEED)\n",
    "    ccp_alpha_values = [i * 0.1 for i in range(11)]\n",
    "\n",
    "    max_depth_values = range(1, 31, 1)\n",
    "\n",
    "    min_samples_split_values = range(2, 61, 1)\n",
    "\n",
    "    min_samples_leaf_values = range(1, 61, 1)\n",
    "\n",
    "    all_combinations = list(\n",
    "        itertools.product(\n",
    "            ccp_alpha_values,\n",
    "            max_depth_values,\n",
    "            min_samples_split_values,\n",
    "            min_samples_leaf_values,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    selected_combinations: List[Tuple[float, int, int, int]] = random.sample(\n",
    "        all_combinations, NUM_POINTS_RS_DECISION_TREE\n",
    "    )\n",
    "\n",
    "    parameter_names = [\n",
    "        \"model__ccp_alpha\",\n",
    "        \"model__max_depth\",\n",
    "        \"model__min_samples_split\",\n",
    "        \"model__min_samples_leaf\",\n",
    "    ]\n",
    "\n",
    "    config_grid = [\n",
    "        dict(zip(parameter_names, combination)) for combination in selected_combinations\n",
    "    ]\n",
    "\n",
    "    return config_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find optimal default hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find teta*\n",
    "\n",
    "(\n",
    "    optimal_config_decision_tree,\n",
    "    best_summary_score_decision_tree,\n",
    "    history_scores,\n",
    ") = find_optimal_configuration_for_all_datasets(\n",
    "    config_space=get_parameter_grid_decision_tree(),\n",
    "    train_datasets=get_train_datasets(),\n",
    "    test_datasets=get_test_datasets(),\n",
    "    get_model=get_decision_tree_pipeline,\n",
    "    summary_func=np.mean,  # Or np.median for a more robust approach\n",
    ")\n",
    "dump_optimal_config_search_history(\n",
    "    history_scores, \"output_data/decision_tree/optimal_config_search_history.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_scores)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Finding optimal configuration for Decision Tree with random search\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimal_config_decision_tree)\n",
    "print(best_summary_score_decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model with optimal hyperparameters on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_dataset, test_dataset in zip(get_train_datasets(), get_test_datasets()):\n",
    "    optimal_model: Pipeline = get_decision_tree_pipeline()\n",
    "    optimal_model.set_params(**optimal_config_decision_tree)\n",
    "    optimal_model.fit(train_dataset[0], train_dataset[1])\n",
    "    score = optimal_model.score(test_dataset[0], test_dataset[1])\n",
    "    print(\"Optimal decision tree score on dataset : \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best hyperparameters for given dataset with random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find tate^(j)*\n",
    "(\n",
    "    best_decision_tree_configs_for_each_dataset,\n",
    "    list_iteration_scores,\n",
    ") = find_best_configs_in_search_space_with_random_search(\n",
    "    get_pipeline=get_decision_tree_pipeline,\n",
    "    config_space=get_parameter_grid_decision_tree(),\n",
    "    train_datasets=get_train_datasets(),\n",
    "    test_datasets=get_test_datasets(),\n",
    ")\n",
    "for i, iteration_scores in enumerate(list_iteration_scores):\n",
    "    dump_scores_to_csv(\n",
    "        iteration_scores,\n",
    "        f\"output_data/decision_tree/random_search_iteration_scores_dataset_{i}.csv\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, iteration_scores in enumerate(list_iteration_scores):\n",
    "    plt.plot(iteration_scores)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(f\"Decision Tree with Random Search on dataset {i}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate tunability on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find d^j\n",
    "tunability_per_dataset = calculate_tunability_on_each_dataset(\n",
    "    train_datasets=get_train_datasets(),\n",
    "    test_datasets=get_test_datasets(),\n",
    "    best_configs=best_decision_tree_configs_for_each_dataset,\n",
    "    optimal_config=optimal_config_decision_tree,\n",
    "    get_model_pipeline=get_decision_tree_pipeline,\n",
    ")\n",
    "dump_tunability_to_csv(\n",
    "    tunability_per_dataset=tunability_per_dataset,\n",
    "    filepath=\"output_data/decision_tree/random_search_tunability.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunability_data = [tunability_per_dataset]\n",
    "\n",
    "sns.boxplot(data=tunability_data, showfliers=False)\n",
    "\n",
    "# add strip plot\n",
    "sns.stripplot(data=tunability_data, color=\"black\", size=4)\n",
    "\n",
    "# add labels and title\n",
    "plt.xlabel(\"Dataset\")\n",
    "plt.ylabel(\"Tunability\")\n",
    "plt.title(\"Tunability per Dataset of Decision Tree with random search\")\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregated tunability d\n",
    "print(\n",
    "    \"Aggregated tunability d: \"\n",
    "    + str(calculate_aggregate_tunability(tunability_per_dataset))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best hyperparameters for given dataset with bayesian search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bayes_search_space_decision_tree():\n",
    "    return (\n",
    "        {\n",
    "            \"model__ccp_alpha\": Real(0.0, 1.0),\n",
    "            \"model__max_depth\": Integer(1, 30),\n",
    "            \"model__min_samples_split\": Integer(2, 60),\n",
    "            \"model__min_samples_leaf\": Integer(1, 60),\n",
    "        },\n",
    "        NUM_ITER_BAYES,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.int = np.int64  # hack so numpy doesn't complain about missing np.int :)\n",
    "# calculate all configs\n",
    "(\n",
    "    best_configs_for_decision_tree,\n",
    "    histories,\n",
    ") = find_best_configs_in_search_space_with_bayes(\n",
    "    search_space=get_bayes_search_space_decision_tree(),\n",
    "    get_pipeline=get_decision_tree_pipeline,\n",
    "    train_datasets=get_train_datasets(),\n",
    ")\n",
    "for i, history in enumerate(histories):\n",
    "    dump_scores_to_csv(\n",
    "        history, f\"output_data/decision_tree/bayes_iteration_scores_dataset_{i}.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot bayes optimization history for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(histories)):\n",
    "    plt.plot(histories[i])\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\n",
    "        f\"Finding optimal configuration for Decision Tree with bayes search on dataset {i}\"\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate tunability on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunability_per_dataset = calculate_tunability_on_each_dataset(\n",
    "    train_datasets=get_train_datasets(),\n",
    "    test_datasets=get_test_datasets(),\n",
    "    best_configs=best_configs_for_decision_tree,\n",
    "    optimal_config=optimal_config_decision_tree,\n",
    "    get_model_pipeline=get_decision_tree_pipeline,\n",
    ")\n",
    "dump_tunability_to_csv(\n",
    "    tunability_per_dataset=tunability_per_dataset,\n",
    "    filepath=\"output_data/decision_tree/bayes_tunability.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunability_data = [tunability_per_dataset]\n",
    "\n",
    "sns.boxplot(data=tunability_data, showfliers=False)\n",
    "\n",
    "# add strip plot\n",
    "sns.stripplot(data=tunability_data, color=\"black\", size=4)\n",
    "\n",
    "# add labels and title\n",
    "plt.xlabel(\"Dataset\")\n",
    "plt.ylabel(\"Tunability\")\n",
    "plt.title(\"Tunability per Dataset of Decision Tree with bayes search\")\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregated tunability d\n",
    "print(\n",
    "    \"Aggregated tunability d: \"\n",
    "    + str(calculate_aggregate_tunability(tunability_per_dataset))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model and search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elasticnet_pipeline() -> Pipeline:\n",
    "    elastic_net = ElasticNet(max_iter=10000, random_state=SEED)\n",
    "    col_trans: ColumnTransformer = get_column_transformer()\n",
    "    decision_tree_pipeline = Pipeline(\n",
    "        steps=[(\"column_transformer\", col_trans), (\"model\", elastic_net)]\n",
    "    )\n",
    "    return decision_tree_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameter_grid_for_elasticnet():\n",
    "    # parameters space\n",
    "    random.seed(SEED)\n",
    "    alpha = [2**i for i in range(-10, 11, 1)]\n",
    "    l1_ratio = [i * 0.05 for i in range(21)]\n",
    "    all_combinations = list(\n",
    "        itertools.product(\n",
    "            alpha,\n",
    "            l1_ratio,\n",
    "        )\n",
    "    )\n",
    "    selected_combinations: List[Tuple[float, int, int, int]] = random.sample(\n",
    "        all_combinations, NUM_POINTS_RS_ELASTIC_NET\n",
    "    )\n",
    "    parameter_names = [\n",
    "        \"model__alpha\",\n",
    "        \"model__l1_ratio\",\n",
    "    ]\n",
    "\n",
    "    parameters_grid_elasticnet = [\n",
    "        dict(zip(parameter_names, combination)) for combination in selected_combinations\n",
    "    ]\n",
    "    return parameters_grid_elasticnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find optimal default hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find teta*\n",
    "\n",
    "(\n",
    "    optimal_config_elasticnet,\n",
    "    best_summary_score_elasticnet,\n",
    "    history_scores,\n",
    ") = find_optimal_configuration_for_all_datasets(\n",
    "    config_space=get_parameter_grid_for_elasticnet(),\n",
    "    train_datasets=get_train_datasets(),\n",
    "    test_datasets=get_test_datasets(),\n",
    "    get_model=get_elasticnet_pipeline,\n",
    "    summary_func=np.mean,  # Or np.median for a more robust approach\n",
    ")\n",
    "dump_optimal_config_search_history(\n",
    "    history_scores, \"output_data/elasticnet/optimal_config_search_history.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_scores)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Finding optimal configuration for ElasticNet with random search\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimal_config_elasticnet)\n",
    "print(best_summary_score_elasticnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model with optimal hyperparameters on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_dataset, test_dataset in zip(get_train_datasets(), get_test_datasets()):\n",
    "    optimal_model: Pipeline = get_elasticnet_pipeline()\n",
    "    optimal_model.set_params(**optimal_config_elasticnet)\n",
    "    optimal_model.fit(train_dataset[0], train_dataset[1])\n",
    "    score = optimal_model.score(test_dataset[0], test_dataset[1])\n",
    "    print(\"Optimal elasticnet score on dataset : \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best hyperparameters for given dataset with random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find tate^(j)*\n",
    "(\n",
    "    best_elasticnet_configs_for_each_dataset,\n",
    "    list_iteration_scores,\n",
    ") = find_best_configs_in_search_space_with_random_search(\n",
    "    get_pipeline=get_elasticnet_pipeline,\n",
    "    config_space=get_parameter_grid_for_elasticnet(),\n",
    "    train_datasets=get_train_datasets(),\n",
    "    test_datasets=get_test_datasets(),\n",
    ")\n",
    "for i, iteration_scores in enumerate(list_iteration_scores):\n",
    "    dump_scores_to_csv(\n",
    "        iteration_scores,\n",
    "        f\"output_data/elasticnet/random_search_iteration_scores_dataset_{i}.csv\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, iteration_scores in enumerate(list_iteration_scores):\n",
    "    plt.plot(iteration_scores)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(f\"ElasticNet with Random Search on dataset {i}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate tunability on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find d^j\n",
    "\n",
    "tunability_per_dataset = calculate_tunability_on_each_dataset(\n",
    "    train_datasets=get_train_datasets(),\n",
    "    test_datasets=get_test_datasets(),\n",
    "    best_configs=best_elasticnet_configs_for_each_dataset,\n",
    "    optimal_config=optimal_config_elasticnet,\n",
    "    get_model_pipeline=get_elasticnet_pipeline,\n",
    ")\n",
    "dump_tunability_to_csv(\n",
    "    tunability_per_dataset=tunability_per_dataset,\n",
    "    filepath=\"output_data/elasticnet/random_search_tunability.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunability_data = [tunability_per_dataset]\n",
    "\n",
    "sns.boxplot(data=tunability_data, showfliers=False)\n",
    "\n",
    "# add strip plot\n",
    "sns.stripplot(data=tunability_data, color=\"black\", size=4)\n",
    "\n",
    "# add labels and title\n",
    "plt.xlabel(\"Dataset\")\n",
    "plt.ylabel(\"Tunability\")\n",
    "plt.title(\"Tunability per dataset of ElasticNet with Random Search\")\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregated tunability d\n",
    "print(\n",
    "    \"Aggregated tunability d: \"\n",
    "    + str(calculate_aggregate_tunability(tunability_per_dataset))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best hyperparameters for given dataset with bayesian search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bayes_search_space_elasticnet():\n",
    "    return (\n",
    "        {\n",
    "            \"model__alpha\": Real(2 ** (-10), 2**10),\n",
    "            \"model__l1_ratio\": Real(0.0, 1.0),\n",
    "        },\n",
    "        NUM_ITER_BAYES,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.int = np.int64  # hack so numpy doesn't complain about missing np.int :)\n",
    "# calculate all configs\n",
    "best_configs_for_elasticnet, histories = find_best_configs_in_search_space_with_bayes(\n",
    "    search_space=get_bayes_search_space_elasticnet(),\n",
    "    get_pipeline=get_elasticnet_pipeline,\n",
    "    train_datasets=get_train_datasets(),\n",
    ")\n",
    "for i, history in enumerate(histories):\n",
    "    dump_scores_to_csv(\n",
    "        history, f\"output_data/elasticnet/bayes_iteration_scores_dataset_{i}.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot bayes optimization history for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(histories)):\n",
    "    plt.plot(histories[i])\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\n",
    "        f\"Finding optimal configuration for ElasticNet with Bayes search on dataset {i}\"\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate tunability on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunability_per_dataset = calculate_tunability_on_each_dataset(\n",
    "    train_datasets=get_train_datasets(),\n",
    "    test_datasets=get_test_datasets(),\n",
    "    best_configs=best_configs_for_elasticnet,\n",
    "    optimal_config=optimal_config_elasticnet,\n",
    "    get_model_pipeline=get_elasticnet_pipeline,\n",
    ")\n",
    "dump_tunability_to_csv(\n",
    "    tunability_per_dataset=tunability_per_dataset,\n",
    "    filepath=\"output_data/elasticnet/bayes_tunability.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunability_data = [tunability_per_dataset]\n",
    "\n",
    "sns.boxplot(data=tunability_data, showfliers=False)\n",
    "\n",
    "# add strip plot\n",
    "sns.stripplot(data=tunability_data, color=\"black\", size=4)\n",
    "\n",
    "# add labels and title\n",
    "plt.xlabel(\"Dataset\")\n",
    "plt.ylabel(\"Tunability\")\n",
    "plt.title(\"Tunability per Dataset of ElasticNet with Bayes search\")\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregated tunability d\n",
    "print(\n",
    "    \"Aggregated tunability d: \"\n",
    "    + str(calculate_aggregate_tunability(tunability_per_dataset))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model and search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_forest_pipeline():\n",
    "    random_forest = RandomForestRegressor(bootstrap=True, random_state=SEED)\n",
    "    col_trans: ColumnTransformer = get_column_transformer()\n",
    "    random_forest_pipeline = Pipeline(\n",
    "        steps=[(\"column_transformer\", col_trans), (\"model\", random_forest)]\n",
    "    )\n",
    "    return random_forest_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameter_grid_for_random_forest():\n",
    "    # parameters space\n",
    "    random.seed(SEED)\n",
    "    # max_depth_values = range(1, 31, 1)\n",
    "    min_samples_split_values = range(2, 528, 5)\n",
    "    min_samples_leaf_values = range(1, 10, 1)\n",
    "    n_estimators_values = range(1, 2000, 10)\n",
    "    max_samples_values = [float(i) * 0.1 for i in range(1, 11, 1)]\n",
    "    max_features_values = [i for i in range(1, 15, 1)]\n",
    "    all_combinations = list(\n",
    "        itertools.product(\n",
    "            # max_depth_values,\n",
    "            min_samples_split_values,\n",
    "            min_samples_leaf_values,\n",
    "            n_estimators_values,\n",
    "            max_samples_values,\n",
    "            max_features_values,\n",
    "        )\n",
    "    )\n",
    "    selected_combinations: List[Tuple[float, int, int, int]] = random.sample(\n",
    "        all_combinations, NUM_POINTS_RS_RANDOM_FOREST\n",
    "    )\n",
    "    parameter_names = [\n",
    "        # \"model__max_depth\",\n",
    "        \"model__min_samples_split\",\n",
    "        \"model__min_samples_leaf\",\n",
    "        \"model__n_estimators\",\n",
    "        \"model__max_samples\",\n",
    "        \"model__max_features\",\n",
    "    ]\n",
    "\n",
    "    parameters_grid_random_forest = [\n",
    "        dict(zip(parameter_names, combination)) for combination in selected_combinations\n",
    "    ]\n",
    "    return parameters_grid_random_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find optimal default hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    optimal_config_random_forest,\n",
    "    best_summary_score_random_forest,\n",
    "    history_scores,\n",
    ") = find_optimal_configuration_for_all_datasets(\n",
    "    config_space=get_parameter_grid_for_random_forest(),\n",
    "    train_datasets=get_train_datasets(),\n",
    "    test_datasets=get_test_datasets(),\n",
    "    get_model=get_random_forest_pipeline,\n",
    "    summary_func=np.mean,  # Or np.median for a more robust approach\n",
    ")\n",
    "dump_optimal_config_search_history(\n",
    "    history_scores, \"output_data/random_forest/optimal_config_search_history.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_scores)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Finding optimal configuration for Random Forest with random search\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimal_config_random_forest)\n",
    "print(best_summary_score_random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model with optimal hyperparameters on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_dataset, test_dataset in zip(get_train_datasets(), get_test_datasets()):\n",
    "    optimal_model: Pipeline = get_random_forest_pipeline()\n",
    "    optimal_model.set_params(**optimal_config_random_forest)\n",
    "    optimal_model.fit(train_dataset[0], train_dataset[1])\n",
    "    score = optimal_model.score(test_dataset[0], test_dataset[1])\n",
    "    print(\"Optimal random_forest score on dataset : \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best hyperparameters for given dataset with random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find tate^(j)*\n",
    "(\n",
    "    best_random_forest_configs_for_each_dataset,\n",
    "    list_iteration_scores,\n",
    ") = find_best_configs_in_search_space_with_random_search(\n",
    "    get_pipeline=get_random_forest_pipeline,\n",
    "    config_space=get_parameter_grid_for_random_forest(),\n",
    "    train_datasets=get_train_datasets(),\n",
    "    test_datasets=get_test_datasets(),\n",
    ")\n",
    "for i, iteration_scores in enumerate(list_iteration_scores):\n",
    "    dump_scores_to_csv(\n",
    "        iteration_scores,\n",
    "        f\"output_data/random_forest/random_search_iteration_scores_dataset_{i}.csv\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, iteration_scores in enumerate(list_iteration_scores):\n",
    "    plt.plot(iteration_scores)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(f\"Random Forest with Random Search on dataset {i}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate tunability on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find d^j\n",
    "\n",
    "tunability_per_dataset = calculate_tunability_on_each_dataset(\n",
    "    train_datasets=get_train_datasets(),\n",
    "    test_datasets=get_test_datasets(),\n",
    "    best_configs=best_random_forest_configs_for_each_dataset,\n",
    "    optimal_config=optimal_config_random_forest,\n",
    "    get_model_pipeline=get_random_forest_pipeline,\n",
    ")\n",
    "dump_tunability_to_csv(\n",
    "    tunability_per_dataset=tunability_per_dataset,\n",
    "    filepath=\"output_data/random_forest/random_search_tunability.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunability_data = [tunability_per_dataset]\n",
    "\n",
    "sns.boxplot(data=tunability_data, showfliers=False)\n",
    "\n",
    "# add strip plot\n",
    "sns.stripplot(data=tunability_data, color=\"black\", size=4)\n",
    "\n",
    "# add labels and title\n",
    "plt.xlabel(\"Dataset\")\n",
    "plt.ylabel(\"Tunability\")\n",
    "plt.title(\"Tunability per dataset of RandomForest with Random Search\")\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregated tunability d\n",
    "print(\n",
    "    \"Aggregated tunability d: \"\n",
    "    + str(calculate_aggregate_tunability(tunability_per_dataset))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best hyperparameters for given dataset with bayesian search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bayes_search_space_random_forest():\n",
    "    return (\n",
    "        {\n",
    "            \"model__min_samples_split\": Integer(2, 528),\n",
    "            \"model__min_samples_leaf\": Integer(2, 10),\n",
    "            \"model__min_samples_leaf\": Integer(1, 60),\n",
    "            \"model__n_estimators\": Integer(1, 2000),\n",
    "            \"model__max_samples\": Real(0.1, 1.0),\n",
    "            \"model__max_features\": Integer(1, 14),\n",
    "        },\n",
    "        NUM_ITER_BAYES,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.int = np.int64  # hack so numpy doesn't complain about missing np.int :)\n",
    "# calculate all configs\n",
    "(\n",
    "    best_configs_for_random_forest,\n",
    "    histories,\n",
    ") = find_best_configs_in_search_space_with_bayes(\n",
    "    search_space=get_bayes_search_space_random_forest(),\n",
    "    get_pipeline=get_random_forest_pipeline,\n",
    "    train_datasets=get_train_datasets(),\n",
    ")\n",
    "for i, history in enumerate(histories):\n",
    "    dump_scores_to_csv(\n",
    "        history, f\"output_data/random_forest/bayes_iteration_scores_dataset_{i}.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot bayes optimization history for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(histories)):\n",
    "    plt.plot(histories[i])\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\n",
    "        f\"Finding optimal configuration for Random Forest with Bayes search on dataset {i}\"\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate tunability on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunability_per_dataset = calculate_tunability_on_each_dataset(\n",
    "    train_datasets=get_train_datasets(),\n",
    "    test_datasets=get_test_datasets(),\n",
    "    best_configs=best_configs_for_random_forest,\n",
    "    optimal_config=optimal_config_random_forest,\n",
    "    get_model_pipeline=get_random_forest_pipeline,\n",
    ")\n",
    "dump_tunability_to_csv(\n",
    "    tunability_per_dataset=tunability_per_dataset,\n",
    "    filepath=\"output_data/random_forest/bayes_tunability.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunability_data = [tunability_per_dataset]\n",
    "\n",
    "sns.boxplot(data=tunability_data, showfliers=False)\n",
    "\n",
    "# add strip plot\n",
    "sns.stripplot(data=tunability_data, color=\"black\", size=4)\n",
    "\n",
    "# add labels and title\n",
    "plt.xlabel(\"Dataset\")\n",
    "plt.ylabel(\"Tunability\")\n",
    "plt.title(\"Tunability per Dataset of Random Forest with Bayes search\")\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregated tunability d\n",
    "print(\n",
    "    \"Aggregated tunability d: \"\n",
    "    + str(calculate_aggregate_tunability(tunability_per_dataset))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
