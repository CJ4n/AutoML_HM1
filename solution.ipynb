{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "- ile potrzeba iteracji (random seach, bayes) do uzyskania stabilncyh wyników\n",
    "- trzeba się zastanowić jakie zakres hyper parametrów bierzemy\n",
    "- określić i przeanalizować tunowalność CAŁYCH algorytmów\n",
    "- sprawdić jak zmiana seed w random search wpływa na wyniki tunowalnośći (sampling bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame, Series\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from skopt.space import Integer, Real\n",
    "\n",
    "from utills.dataset import load_dataset_from_id, split_dataset\n",
    "from utills.pipeline import (\n",
    "    evaluate_pipeline_on_datasets,\n",
    "    get_bayes_model,\n",
    "    get_column_transformer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utill functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "\n",
    "\n",
    "def get_bayes_config(\n",
    "    pipeline: Pipeline,\n",
    "    search_space: Dict[str, Any],\n",
    "    X: DataFrame,\n",
    "    y: DataFrame,\n",
    "    n_iter,\n",
    "):\n",
    "\n",
    "    opt: BayesSearchCV = get_bayes_model(pipeline, search_space, n_iter)\n",
    "    opt.fit(X, y)\n",
    "    iteration_scores = opt.cv_results_[\"mean_test_score\"]\n",
    "\n",
    "    # Optional: Print the score for each iteration\n",
    "    for i, score in enumerate(iteration_scores):\n",
    "        print(f\"Iteration {i + 1}: Score = {score}\")\n",
    "    print(opt.n_iter)\n",
    "    return dict(opt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(\n",
    "    model: Pipeline, X_train, y_train, X_test, y_test\n",
    ") -> float:\n",
    "    model.fit(\n",
    "        X=X_train,\n",
    "        y=y_train,\n",
    "    )\n",
    "    return model.score(\n",
    "        X=X_test,\n",
    "        y=y_test,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(\n",
    "    train_datasets: List[Tuple[DataFrame, Series]],\n",
    "    test_datasets: List[Tuple[DataFrame, Series]],\n",
    "    model: Pipeline,\n",
    "    config,\n",
    ") -> List[float]:\n",
    "    performances: List[float] = []\n",
    "    for (X_train, y_train), (X_test, y_test) in zip(train_datasets, test_datasets):\n",
    "        model.set_params(**config)\n",
    "        performance: float = evaluate_model_performance(\n",
    "            model=model, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test\n",
    "        )\n",
    "        performances.append(performance)\n",
    "    return performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_configuration_for_all_datasets(\n",
    "    config_space,\n",
    "    train_datasets: List[Tuple[DataFrame, Series]],\n",
    "    test_datasets: List[Tuple[DataFrame, Series]],\n",
    "    model: Pipeline,\n",
    "    summary_func,\n",
    "):\n",
    "    best_config = None\n",
    "    best_summary_score = float(\"0\")\n",
    "    last_idx_of_config_with_significant_imporvement = -1\n",
    "    for idx, config in enumerate(config_space):\n",
    "        performances = experiment(\n",
    "            train_datasets=train_datasets,\n",
    "            test_datasets=test_datasets,\n",
    "            model=model,\n",
    "            config=config,\n",
    "        )\n",
    "        summary_score = summary_func(performances)\n",
    "\n",
    "        if summary_score > best_summary_score:\n",
    "            if abs(summary_score - best_summary_score) > 0.01:\n",
    "                last_idx_of_config_with_significant_imporvement = idx\n",
    "                best_summary_score = summary_score\n",
    "                best_config = config\n",
    "\n",
    "    return (best_config, last_idx_of_config_with_significant_imporvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_config_for_dataset(\n",
    "    config_space,\n",
    "    train_dataset: Tuple[DataFrame, Series],\n",
    "    test_dataset: Tuple[DataFrame, Series],\n",
    "    model: Pipeline,\n",
    "):\n",
    "    best_config = None\n",
    "    best_score = float(\"0\")\n",
    "\n",
    "    for config in config_space:\n",
    "        # model = get_model_func()\n",
    "        model.set_params(**config)\n",
    "        score: float = evaluate_model_performance(\n",
    "            model=model,\n",
    "            X_train=train_dataset[0],\n",
    "            y_train=train_dataset[1],\n",
    "            X_test=test_dataset[0],\n",
    "            y_test=test_dataset[1],\n",
    "        )\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_config = config\n",
    "\n",
    "    return best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_bayes_config_for_dataset(\n",
    "    config_space,\n",
    "    train_dataset: Tuple[DataFrame, Series],\n",
    "    test_dataset: Tuple[DataFrame, Series],\n",
    "    pipeline: Pipeline,\n",
    "    retries: int = 1,\n",
    "):\n",
    "    best_config = None\n",
    "    best_score = float(\"0\")\n",
    "    steps = -1\n",
    "\n",
    "    for config in config_space:\n",
    "        for _ in range(retries):\n",
    "            cnf = get_bayes_config(pipeline, config, train_dataset[0], train_dataset[1])\n",
    "\n",
    "            pipeline.set_params(**cnf)\n",
    "            score: float = evaluate_model_performance(\n",
    "                model=pipeline,\n",
    "                X_train=train_dataset[0],\n",
    "                y_train=train_dataset[1],\n",
    "                X_test=test_dataset[0],\n",
    "                y_test=test_dataset[1],\n",
    "            )\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_config = cnf\n",
    "\n",
    "    return (best_config, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_bayes_config_for_each_dataset(\n",
    "    config_space,\n",
    "    train_datasets: List[Tuple[DataFrame, Series]],\n",
    "    test_datasets: List[Tuple[DataFrame, Series]],\n",
    "    pipeline: Pipeline,\n",
    "    retries: int = 1,\n",
    "):\n",
    "    configs = []\n",
    "    for train, test in zip(train_datasets, test_datasets):\n",
    "        cnf = find_optimal_bayes_config_for_dataset(\n",
    "            config_space, train, test, pipeline, retries\n",
    "        )\n",
    "        configs.append(cnf[0])\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configs_from_candidates(candidates, pipeline: Pipeline, train_datasets, retries):\n",
    "    configs = []\n",
    "    for config in candidates:\n",
    "        for train in train_datasets:\n",
    "            for _ in range(retries):\n",
    "                cnf = get_bayes_config(\n",
    "                    pipeline, config[0][0], train[0], train[1], config[0][1]\n",
    "                )\n",
    "                configs.append(cnf)\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AutoML_HM1\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AutoML_HM1\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AutoML_HM1\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AutoML_HM1\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "fish_market_dataset_id = (\n",
    "    43308  # https://www.openml.org/search?type=data&id=43308&sort=runs&status=active\n",
    ")\n",
    "liver_disorders_dataset_id = (\n",
    "    8  # https://www.openml.org/search?type=data&id=8&sort=runs&status=active\n",
    ")\n",
    "diabetes_dataset_id = (\n",
    "    44223  # https://www.openml.org/search?type=data&id=44223&sort=runs&status=active\n",
    ")\n",
    "\n",
    "lisbona_house_prices_dataset_id = (\n",
    "    43660  # https://www.openml.org/search?type=data&id=43660&sort=runs&status=active\n",
    ")\n",
    "\n",
    "\n",
    "fish_market_dataset: DataFrame = load_dataset_from_id(id=fish_market_dataset_id)\n",
    "fish_market_regression_class = \"Weight\"\n",
    "\n",
    "liver_disorders_dataset: DataFrame = load_dataset_from_id(id=liver_disorders_dataset_id)\n",
    "liver_disorders_regression_class = \"drinks\"\n",
    "diabetes_dataset: DataFrame = load_dataset_from_id(id=diabetes_dataset_id)\n",
    "diabetes_regression_class = \"class\"\n",
    "\n",
    "lisbona_house_prices_dataset: DataFrame = load_dataset_from_id(\n",
    "    id=lisbona_house_prices_dataset_id\n",
    ")\n",
    "lisbona_house_prices_regression_class = \"Price\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_train_fish_market,\n",
    "    X_test_fish_market,\n",
    "    y_train_fish_market,\n",
    "    y_test_fish_market,\n",
    ") = split_dataset(data=fish_market_dataset, class_=fish_market_regression_class)\n",
    "\n",
    "(\n",
    "    X_train_liver_disorders,\n",
    "    X_test_liver_disorders,\n",
    "    y_train_liver_disorders,\n",
    "    y_test_liver_disorders,\n",
    ") = split_dataset(data=liver_disorders_dataset, class_=liver_disorders_regression_class)\n",
    "\n",
    "X_train_diabetes, X_test_diabetes, y_train_diabetes, y_test_diabetes = split_dataset(\n",
    "    diabetes_dataset, diabetes_regression_class\n",
    ")\n",
    "\n",
    "(\n",
    "    X_train_lisbona_house_prices,\n",
    "    X_test_lisbona_house_prices,\n",
    "    y_train_lisbona_house_prices,\n",
    "    y_test_lisbona_house_prices,\n",
    ") = split_dataset(lisbona_house_prices_dataset, lisbona_house_prices_regression_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_datasets() -> List[Tuple[DataFrame, Series]]:\n",
    "    return [\n",
    "        (X_train_fish_market, y_train_fish_market),\n",
    "        (X_train_liver_disorders, y_train_liver_disorders),\n",
    "        (X_train_diabetes, y_train_diabetes),\n",
    "        (X_train_lisbona_house_prices, y_train_lisbona_house_prices),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_datasets():\n",
    "    return [\n",
    "        (X_test_fish_market, y_test_fish_market),\n",
    "        (X_test_liver_disorders, y_test_liver_disorders),\n",
    "        (X_test_diabetes, y_test_diabetes),\n",
    "        (X_test_lisbona_house_prices, y_test_lisbona_house_prices),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create generic column transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decision_tree_pipeline() -> Pipeline:\n",
    "    decision_tree = DecisionTreeRegressor()\n",
    "    col_trans: ColumnTransformer = get_column_transformer()\n",
    "    decision_tree_pipeline = Pipeline(\n",
    "        steps=[(\"column_transformer\", col_trans), (\"model\", decision_tree)]\n",
    "    )\n",
    "    return decision_tree_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_configuration_grid_decision_tree():\n",
    "    # parameters space\n",
    "    random.seed(42)\n",
    "    ccp_alpha_values = [i * 0.1 for i in range(11)]\n",
    "\n",
    "    max_depth_values = range(1, 31, 1)\n",
    "\n",
    "    min_samples_split_values = range(2, 61, 1)\n",
    "\n",
    "    min_samples_leaf_values = range(1, 61, 1)\n",
    "\n",
    "    all_combinations = list(\n",
    "        itertools.product(\n",
    "            ccp_alpha_values,\n",
    "            max_depth_values,\n",
    "            min_samples_split_values,\n",
    "            min_samples_leaf_values,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    selected_combinations: List[Tuple[float, int, int, int]] = random.sample(\n",
    "        all_combinations, 100\n",
    "    )\n",
    "\n",
    "    parameter_names = [\n",
    "        \"model__ccp_alpha\",\n",
    "        \"model__max_depth\",\n",
    "        \"model__min_samples_split\",\n",
    "        \"model__min_samples_leaf\",\n",
    "    ]\n",
    "\n",
    "    config_grid = [\n",
    "        dict(zip(parameter_names, combination)) for combination in selected_combinations\n",
    "    ]\n",
    "\n",
    "    return config_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets: List[Tuple[DataFrame, Series]] = get_train_datasets()\n",
    "test_datasets: List[Tuple[DataFrame, Series]] = get_test_datasets()\n",
    "decison_tree_pipeline: Pipeline = get_decision_tree_pipeline()\n",
    "configuration_grid_decision_tree = get_configuration_grid_decision_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find teta*\n",
    "\n",
    "(\n",
    "    optimal_config_decision_tree,\n",
    "    last_idx_of_config_with_significant_imporvement,\n",
    ") = find_optimal_configuration_for_all_datasets(\n",
    "    config_space=configuration_grid_decision_tree,\n",
    "    train_datasets=train_datasets,\n",
    "    test_datasets=test_datasets,\n",
    "    model=decison_tree_pipeline,\n",
    "    summary_func=np.mean,  # Or np.median for a more robust approach\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__ccp_alpha': 0.7000000000000001, 'model__max_depth': 5, 'model__min_samples_split': 16, 'model__min_samples_leaf': 4}\n",
      "46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;column_transformer&#x27;,\n",
       "                 ColumnTransformer(n_jobs=-1,\n",
       "                                   transformers=[(&#x27;num_pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;scale&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002126041C610&gt;),\n",
       "                                                 (&#x27;cat_pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;one-hot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002126041CF70&gt;)])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 DecisionTreeRegressor(ccp_alpha=0.7000000000000001,\n",
       "                                       max_depth=5, min_samples_leaf=4,\n",
       "                                       min_samples_split=16))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;column_transformer&#x27;,\n",
       "                 ColumnTransformer(n_jobs=-1,\n",
       "                                   transformers=[(&#x27;num_pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;scale&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002126041C610&gt;),\n",
       "                                                 (&#x27;cat_pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;one-hot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002126041CF70&gt;)])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 DecisionTreeRegressor(ccp_alpha=0.7000000000000001,\n",
       "                                       max_depth=5, min_samples_leaf=4,\n",
       "                                       min_samples_split=16))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">column_transformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(n_jobs=-1,\n",
       "                  transformers=[(&#x27;num_pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;impute&#x27;, SimpleImputer()),\n",
       "                                                 (&#x27;scale&#x27;, MinMaxScaler())]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002126041C610&gt;),\n",
       "                                (&#x27;cat_pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;one-hot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=False))]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002126041CF70&gt;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num_pipeline</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002126041C610&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat_pipeline</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002126041CF70&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse=False)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=5,\n",
       "                      min_samples_leaf=4, min_samples_split=16)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('column_transformer',\n",
       "                 ColumnTransformer(n_jobs=-1,\n",
       "                                   transformers=[('num_pipeline',\n",
       "                                                  Pipeline(steps=[('impute',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('scale',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x000002126041C610>),\n",
       "                                                 ('cat_pipeline',\n",
       "                                                  Pipeline(steps=[('impute',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('one-hot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x000002126041CF70>)])),\n",
       "                ('model',\n",
       "                 DecisionTreeRegressor(ccp_alpha=0.7000000000000001,\n",
       "                                       max_depth=5, min_samples_leaf=4,\n",
       "                                       min_samples_split=16))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(optimal_config_decision_tree)\n",
    "print(last_idx_of_config_with_significant_imporvement)\n",
    "optimal_decision_tree = get_decision_tree_pipeline()\n",
    "optimal_decision_tree.set_params(**optimal_config_decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_configs_for_each_set(\n",
    "    pipeline: Pipeline, config_space, train_datasets, test_datasets\n",
    "):\n",
    "    best_configs = []\n",
    "    for train_dataset, test_dataset in zip(train_datasets, test_datasets):\n",
    "        best_config = find_optimal_config_for_dataset(\n",
    "            config_space=config_space,\n",
    "            train_dataset=train_dataset,\n",
    "            test_dataset=test_dataset,\n",
    "            model=pipeline,\n",
    "        )\n",
    "        best_configs.append(best_config)\n",
    "        pipeline.set_params(**best_config)\n",
    "        pipeline.fit(train_dataset[0], train_dataset[1])\n",
    "        print(\"score: \" + str(pipeline.score(test_dataset[0], test_dataset[1])))\n",
    "        print(\"best config: \" + str(best_config))\n",
    "    return best_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9643548213621457\n",
      "best config: {'model__ccp_alpha': 0.7000000000000001, 'model__max_depth': 5, 'model__min_samples_split': 16, 'model__min_samples_leaf': 4}\n",
      "score: 0.1878010532545623\n",
      "best config: {'model__ccp_alpha': 0.2, 'model__max_depth': 25, 'model__min_samples_split': 39, 'model__min_samples_leaf': 44}\n",
      "score: 0.46184442507636947\n",
      "best config: {'model__ccp_alpha': 0.4, 'model__max_depth': 18, 'model__min_samples_split': 51, 'model__min_samples_leaf': 6}\n",
      "score: 0.698117764128138\n",
      "best config: {'model__ccp_alpha': 0.7000000000000001, 'model__max_depth': 5, 'model__min_samples_split': 16, 'model__min_samples_leaf': 4}\n"
     ]
    }
   ],
   "source": [
    "# find tate^(j)*\n",
    "best_configs_for_each_dataset = get_best_configs_for_each_set(\n",
    "    pipeline=get_decision_tree_pipeline(),\n",
    "    config_space=get_configuration_grid_decision_tree(),\n",
    "    train_datasets=get_train_datasets(),\n",
    "    test_datasets=get_test_datasets(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tunability_on_each_set(train_datasets, test_datasets, best_configs):\n",
    "    tunability = []\n",
    "    for train_dataset, test_dataset, best_config in zip(\n",
    "        train_datasets, test_datasets, best_configs\n",
    "    ):\n",
    "        optimal_decision_tree.fit(train_dataset[0], train_dataset[1])\n",
    "        best_decision_tree_for_dataset = get_decision_tree_pipeline()\n",
    "        best_decision_tree_for_dataset.set_params(**best_config)\n",
    "        best_decision_tree_for_dataset.fit(train_dataset[0], train_dataset[1])\n",
    "        tunability_on_dataset = best_decision_tree_for_dataset.score(\n",
    "            test_dataset[0], test_dataset[1]\n",
    "        ) - optimal_decision_tree.score(test_dataset[0], test_dataset[1])\n",
    "        tunability.append(tunability_on_dataset)\n",
    "        print(\"d^j: \" + str(tunability_on_dataset))\n",
    "    return tunability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d^j: 0.0\n",
      "d^j: 0.12012499127253262\n",
      "d^j: 0.0945803993458324\n",
      "d^j: 0.0\n"
     ]
    }
   ],
   "source": [
    "# find d^j\n",
    "tunability_on_datasets = calculate_tunability_on_each_set(\n",
    "    get_train_datasets(), get_test_datasets(), best_configs_for_each_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tunability data\n",
    "tunability_data = [tunability_on_datasets]\n",
    "\n",
    "# create box plot\n",
    "sns.boxplot(data=tunability_data)\n",
    "\n",
    "# add strip plot\n",
    "sns.stripplot(data=tunability_data, color=\"black\", size=4)\n",
    "\n",
    "# add labels and title\n",
    "plt.xlabel(\"Dataset\")\n",
    "plt.ylabel(\"Tunability\")\n",
    "plt.title(\"Tunability per Dataset\")\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated tunability d: 0.053676347654591255\n"
     ]
    }
   ],
   "source": [
    "# aggregated tunability d\n",
    "print(\"Aggregated tunability d: \" + str(np.mean(tunability_on_datasets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores_for_pipeline(pipeline: Pipeline, train_datasets, test_datasets):\n",
    "    scores = []\n",
    "    for train_dataset, test_dataset in zip(train_datasets, test_datasets):\n",
    "        pipeline.fit(train_dataset[0], train_dataset[1])\n",
    "        score = pipeline.score(test_dataset[0], test_dataset[1])\n",
    "        scores.append(score)\n",
    "        print(\"score: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9643548213621457\n",
      "score: 0.06767606198202969\n",
      "score: 0.36726402573053707\n",
      "score: 0.698117764128138\n"
     ]
    }
   ],
   "source": [
    "calculate_scores_for_pipeline(\n",
    "    optimal_decision_tree, get_train_datasets(), get_test_datasets()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=6, min_samples_leaf=19,\n",
      "                      min_samples_split=58)\n",
      "Test score R^2: 0.7815269691092457\n",
      "Train score R^2: 0.7815269691092457\n",
      "Mean Squared Error: 26856.500884781224\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=6, min_samples_leaf=19,\n",
      "                      min_samples_split=58)\n",
      "Test score R^2: 0.15528101406816253\n",
      "Train score R^2: 0.15528101406816253\n",
      "Mean Squared Error: 9.48162852008955\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=6, min_samples_leaf=19,\n",
      "                      min_samples_split=58)\n",
      "Test score R^2: 0.5221465690813645\n",
      "Train score R^2: 0.5221465690813645\n",
      "Mean Squared Error: 2903.6276381318785\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=6, min_samples_leaf=19,\n",
      "                      min_samples_split=58)\n",
      "Test score R^2: 0.5595820029015193\n",
      "Train score R^2: 0.5595820029015193\n",
      "Mean Squared Error: 89991302260.828\n",
      "Parameter set: DecisionTreeRegressor(max_depth=15, min_samples_leaf=12, min_samples_split=50)\n",
      "Test score R^2: 0.789919150538415\n",
      "Train score R^2: 0.789919150538415\n",
      "Mean Squared Error: 25824.864956727335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter set: DecisionTreeRegressor(max_depth=15, min_samples_leaf=12, min_samples_split=50)\n",
      "Test score R^2: 0.24069100272757193\n",
      "Train score R^2: 0.24069100272757193\n",
      "Mean Squared Error: 8.522935986997926\n",
      "Parameter set: DecisionTreeRegressor(max_depth=15, min_samples_leaf=12, min_samples_split=50)\n",
      "Test score R^2: 0.5450218184758296\n",
      "Train score R^2: 0.5450218184758296\n",
      "Mean Squared Error: 2764.6285181648223\n",
      "Parameter set: DecisionTreeRegressor(max_depth=15, min_samples_leaf=12, min_samples_split=50)\n",
      "Test score R^2: 0.7132709369960079\n",
      "Train score R^2: 0.7132709369960079\n",
      "Mean Squared Error: 58587800557.08415\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=13, min_samples_leaf=59,\n",
      "                      min_samples_split=56)\n",
      "Test score R^2: 0.6191250374142274\n",
      "Train score R^2: 0.6191250374142274\n",
      "Mean Squared Error: 46820.28133161539\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=13, min_samples_leaf=59,\n",
      "                      min_samples_split=56)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=13, min_samples_leaf=59,\n",
      "                      min_samples_split=56)\n",
      "Test score R^2: 0.43254023226744\n",
      "Train score R^2: 0.43254023226744\n",
      "Mean Squared Error: 3448.111405098839\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=13, min_samples_leaf=59,\n",
      "                      min_samples_split=56)\n",
      "Test score R^2: 0.4859759704370552\n",
      "Train score R^2: 0.4859759704370552\n",
      "Mean Squared Error: 105031338679.34148\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=26, min_samples_leaf=36,\n",
      "                      min_samples_split=6)\n",
      "Test score R^2: 0.7765160292190798\n",
      "Train score R^2: 0.7765160292190798\n",
      "Mean Squared Error: 27472.4868078269\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=26, min_samples_leaf=36,\n",
      "                      min_samples_split=6)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=26, min_samples_leaf=36,\n",
      "                      min_samples_split=6)\n",
      "Test score R^2: 0.4794698155499745\n",
      "Train score R^2: 0.4794698155499745\n",
      "Mean Squared Error: 3162.94857849065\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=26, min_samples_leaf=36,\n",
      "                      min_samples_split=6)\n",
      "Test score R^2: 0.5296159165459413\n",
      "Train score R^2: 0.5296159165459413\n",
      "Mean Squared Error: 96114319831.78322\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=13, min_samples_leaf=47,\n",
      "                      min_samples_split=15)\n",
      "Test score R^2: 0.674980824248782\n",
      "Train score R^2: 0.674980824248782\n",
      "Mean Squared Error: 39954.028859050595\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=13, min_samples_leaf=47,\n",
      "                      min_samples_split=15)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=13, min_samples_leaf=47,\n",
      "                      min_samples_split=15)\n",
      "Test score R^2: 0.4634973366499989\n",
      "Train score R^2: 0.4634973366499989\n",
      "Mean Squared Error: 3260.0037175409007\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=13, min_samples_leaf=47,\n",
      "                      min_samples_split=15)\n",
      "Test score R^2: 0.5157035955123616\n",
      "Train score R^2: 0.5157035955123616\n",
      "Mean Squared Error: 98957046276.9575\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=23, min_samples_leaf=13,\n",
      "                      min_samples_split=41)\n",
      "Test score R^2: 0.789919150538415\n",
      "Train score R^2: 0.789919150538415\n",
      "Mean Squared Error: 25824.864956727335\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=23, min_samples_leaf=13,\n",
      "                      min_samples_split=41)\n",
      "Test score R^2: 0.2639431943639722\n",
      "Train score R^2: 0.2639431943639722\n",
      "Mean Squared Error: 8.261939552626234\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=23, min_samples_leaf=13,\n",
      "                      min_samples_split=41)\n",
      "Test score R^2: 0.5565776581396269\n",
      "Train score R^2: 0.5565776581396269\n",
      "Mean Squared Error: 2694.410636993356\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=23, min_samples_leaf=13,\n",
      "                      min_samples_split=41)\n",
      "Test score R^2: 0.7132709369960079\n",
      "Train score R^2: 0.7132709369960079\n",
      "Mean Squared Error: 58587800557.08415\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=1, min_samples_leaf=28,\n",
      "                      min_samples_split=44)\n",
      "Test score R^2: 0.6950440400288784\n",
      "Train score R^2: 0.6950440400288784\n",
      "Mean Squared Error: 37487.69344843805\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=1, min_samples_leaf=28,\n",
      "                      min_samples_split=44)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=1, min_samples_leaf=28,\n",
      "                      min_samples_split=44)\n",
      "Test score R^2: 0.30430942765565605\n",
      "Train score R^2: 0.30430942765565605\n",
      "Mean Squared Error: 4227.292811445302\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=1, min_samples_leaf=28,\n",
      "                      min_samples_split=44)\n",
      "Test score R^2: 0.45902318512499396\n",
      "Train score R^2: 0.45902318512499396\n",
      "Mean Squared Error: 110538643707.22058\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=24, min_samples_leaf=57,\n",
      "                      min_samples_split=6)\n",
      "Test score R^2: 0.6328118884390866\n",
      "Train score R^2: 0.6328118884390866\n",
      "Mean Squared Error: 45137.78109275156\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=24, min_samples_leaf=57,\n",
      "                      min_samples_split=6)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=24, min_samples_leaf=57,\n",
      "                      min_samples_split=6)\n",
      "Test score R^2: 0.43684482413295955\n",
      "Train score R^2: 0.43684482413295955\n",
      "Mean Squared Error: 3421.9549916404862\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=24, min_samples_leaf=57,\n",
      "                      min_samples_split=6)\n",
      "Test score R^2: 0.48975175804838733\n",
      "Train score R^2: 0.48975175804838733\n",
      "Mean Squared Error: 104259826056.23653\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=22, min_samples_leaf=44,\n",
      "                      min_samples_split=31)\n",
      "Test score R^2: 0.674980824248782\n",
      "Train score R^2: 0.674980824248782\n",
      "Mean Squared Error: 39954.028859050595\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=22, min_samples_leaf=44,\n",
      "                      min_samples_split=31)\n",
      "Test score R^2: 0.1809270356624959\n",
      "Train score R^2: 0.1809270356624959\n",
      "Mean Squared Error: 9.193762313900969\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=22, min_samples_leaf=44,\n",
      "                      min_samples_split=31)\n",
      "Test score R^2: 0.47574569176031156\n",
      "Train score R^2: 0.47574569176031156\n",
      "Mean Squared Error: 3185.5778368862666\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=22, min_samples_leaf=44,\n",
      "                      min_samples_split=31)\n",
      "Test score R^2: 0.5253118659699338\n",
      "Train score R^2: 0.5253118659699338\n",
      "Mean Squared Error: 96993773257.58125\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.8, max_depth=10, min_samples_leaf=15,\n",
      "                      min_samples_split=58)\n",
      "Test score R^2: 0.7815269691092457\n",
      "Train score R^2: 0.7815269691092457\n",
      "Mean Squared Error: 26856.500884781224\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.8, max_depth=10, min_samples_leaf=15,\n",
      "                      min_samples_split=58)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.8, max_depth=10, min_samples_leaf=15,\n",
      "                      min_samples_split=58)\n",
      "Test score R^2: 0.5227000242383976\n",
      "Train score R^2: 0.5227000242383976\n",
      "Mean Squared Error: 2900.264624315406\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.8, max_depth=10, min_samples_leaf=15,\n",
      "                      min_samples_split=58)\n",
      "Test score R^2: 0.5595820029015193\n",
      "Train score R^2: 0.5595820029015193\n",
      "Mean Squared Error: 89991302260.828\n",
      "Parameter set: DecisionTreeRegressor(max_depth=19, min_samples_leaf=54, min_samples_split=50)\n",
      "Test score R^2: 0.6441798202604005\n",
      "Train score R^2: 0.6441798202604005\n",
      "Mean Squared Error: 43740.34146474588\n",
      "Parameter set: DecisionTreeRegressor(max_depth=19, min_samples_leaf=54, min_samples_split=50)\n",
      "Test score R^2: 0.15650060819389422\n",
      "Train score R^2: 0.15650060819389422\n",
      "Mean Squared Error: 9.46793906994334\n",
      "Parameter set: DecisionTreeRegressor(max_depth=19, min_samples_leaf=54, min_samples_split=50)\n",
      "Test score R^2: 0.43684482413295955\n",
      "Train score R^2: 0.43684482413295955\n",
      "Mean Squared Error: 3421.9549916404862\n",
      "Parameter set: DecisionTreeRegressor(max_depth=19, min_samples_leaf=54, min_samples_split=50)\n",
      "Test score R^2: 0.4931640505110051\n",
      "Train score R^2: 0.4931640505110051\n",
      "Mean Squared Error: 103562586968.75864\n",
      "Parameter set: DecisionTreeRegressor(max_depth=18, min_samples_leaf=30, min_samples_split=40)\n",
      "Test score R^2: 0.7815269691092457\n",
      "Train score R^2: 0.7815269691092457\n",
      "Mean Squared Error: 26856.500884781224\n",
      "Parameter set: DecisionTreeRegressor(max_depth=18, min_samples_leaf=30, min_samples_split=40)\n",
      "Test score R^2: 0.1981026136312567\n",
      "Train score R^2: 0.1981026136312567\n",
      "Mean Squared Error: 9.000973407022101\n",
      "Parameter set: DecisionTreeRegressor(max_depth=18, min_samples_leaf=30, min_samples_split=40)\n",
      "Test score R^2: 0.48146213781166225\n",
      "Train score R^2: 0.48146213781166225\n",
      "Mean Squared Error: 3150.8424354585054\n",
      "Parameter set: DecisionTreeRegressor(max_depth=18, min_samples_leaf=30, min_samples_split=40)\n",
      "Test score R^2: 0.5362524536474875\n",
      "Train score R^2: 0.5362524536474875\n",
      "Mean Squared Error: 94758265764.49924\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=26, min_samples_leaf=54,\n",
      "                      min_samples_split=31)\n",
      "Test score R^2: 0.6441798202604005\n",
      "Train score R^2: 0.6441798202604005\n",
      "Mean Squared Error: 43740.34146474588\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=26, min_samples_leaf=54,\n",
      "                      min_samples_split=31)\n",
      "Test score R^2: 0.15650060819389422\n",
      "Train score R^2: 0.15650060819389422\n",
      "Mean Squared Error: 9.46793906994334\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=26, min_samples_leaf=54,\n",
      "                      min_samples_split=31)\n",
      "Test score R^2: 0.43684482413295955\n",
      "Train score R^2: 0.43684482413295955\n",
      "Mean Squared Error: 3421.9549916404862\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=26, min_samples_leaf=54,\n",
      "                      min_samples_split=31)\n",
      "Test score R^2: 0.4931640505110051\n",
      "Train score R^2: 0.4931640505110051\n",
      "Mean Squared Error: 103562586968.75864\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=10, min_samples_leaf=58,\n",
      "                      min_samples_split=32)\n",
      "Test score R^2: 0.6247132560729404\n",
      "Train score R^2: 0.6247132560729404\n",
      "Mean Squared Error: 46133.33155689871\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=10, min_samples_leaf=58,\n",
      "                      min_samples_split=32)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=10, min_samples_leaf=58,\n",
      "                      min_samples_split=32)\n",
      "Test score R^2: 0.43254023226744\n",
      "Train score R^2: 0.43254023226744\n",
      "Mean Squared Error: 3448.111405098839\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=10, min_samples_leaf=58,\n",
      "                      min_samples_split=32)\n",
      "Test score R^2: 0.48975175804838733\n",
      "Train score R^2: 0.48975175804838733\n",
      "Mean Squared Error: 104259826056.23653\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=18, min_samples_leaf=6,\n",
      "                      min_samples_split=51)\n",
      "Test score R^2: 0.789919150538415\n",
      "Train score R^2: 0.789919150538415\n",
      "Mean Squared Error: 25824.864956727335\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=18, min_samples_leaf=6,\n",
      "                      min_samples_split=51)\n",
      "Test score R^2: 0.19718855402571\n",
      "Train score R^2: 0.19718855402571\n",
      "Mean Squared Error: 9.011233355915582\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=18, min_samples_leaf=6,\n",
      "                      min_samples_split=51)\n",
      "Test score R^2: 0.5747918915000031\n",
      "Train score R^2: 0.5747918915000031\n",
      "Mean Squared Error: 2583.733705594328\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=18, min_samples_leaf=6,\n",
      "                      min_samples_split=51)\n",
      "Test score R^2: 0.7423932765727297\n",
      "Train score R^2: 0.7423932765727297\n",
      "Mean Squared Error: 52637187092.92724\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.9, max_depth=30, min_samples_leaf=27,\n",
      "                      min_samples_split=24)\n",
      "Test score R^2: 0.789919150538415\n",
      "Train score R^2: 0.789919150538415\n",
      "Mean Squared Error: 25824.864956727335\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.9, max_depth=30, min_samples_leaf=27,\n",
      "                      min_samples_split=24)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.9, max_depth=30, min_samples_leaf=27,\n",
      "                      min_samples_split=24)\n",
      "Test score R^2: 0.5213709259235062\n",
      "Train score R^2: 0.5213709259235062\n",
      "Mean Squared Error: 2908.3407546750736\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.9, max_depth=30, min_samples_leaf=27,\n",
      "                      min_samples_split=24)\n",
      "Test score R^2: 0.5504928637189375\n",
      "Train score R^2: 0.5504928637189375\n",
      "Mean Squared Error: 91848500370.03145\n",
      "Parameter set: DecisionTreeRegressor(max_depth=16, min_samples_leaf=30, min_samples_split=44)\n",
      "Test score R^2: 0.7815269691092457\n",
      "Train score R^2: 0.7815269691092457\n",
      "Mean Squared Error: 26856.500884781224\n",
      "Parameter set: DecisionTreeRegressor(max_depth=16, min_samples_leaf=30, min_samples_split=44)\n",
      "Test score R^2: 0.1981026136312567\n",
      "Train score R^2: 0.1981026136312567\n",
      "Mean Squared Error: 9.000973407022101\n",
      "Parameter set: DecisionTreeRegressor(max_depth=16, min_samples_leaf=30, min_samples_split=44)\n",
      "Test score R^2: 0.48146213781166225\n",
      "Train score R^2: 0.48146213781166225\n",
      "Mean Squared Error: 3150.8424354585054\n",
      "Parameter set: DecisionTreeRegressor(max_depth=16, min_samples_leaf=30, min_samples_split=44)\n",
      "Test score R^2: 0.5362524536474875\n",
      "Train score R^2: 0.5362524536474875\n",
      "Mean Squared Error: 94758265764.49924\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=28,\n",
      "                      min_samples_leaf=53, min_samples_split=48)\n",
      "Test score R^2: 0.6441798202604005\n",
      "Train score R^2: 0.6441798202604005\n",
      "Mean Squared Error: 43740.34146474588\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=28,\n",
      "                      min_samples_leaf=53, min_samples_split=48)\n",
      "Test score R^2: 0.14250945833885176\n",
      "Train score R^2: 0.14250945833885176\n",
      "Mean Squared Error: 9.624984060885597\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=28,\n",
      "                      min_samples_leaf=53, min_samples_split=48)\n",
      "Test score R^2: 0.43684482413295955\n",
      "Train score R^2: 0.43684482413295955\n",
      "Mean Squared Error: 3421.9549916404862\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=28,\n",
      "                      min_samples_leaf=53, min_samples_split=48)\n",
      "Test score R^2: 0.4931640505110051\n",
      "Train score R^2: 0.4931640505110051\n",
      "Mean Squared Error: 103562586968.75864\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=23, min_samples_leaf=6,\n",
      "                      min_samples_split=51)\n",
      "Test score R^2: 0.789919150538415\n",
      "Train score R^2: 0.789919150538415\n",
      "Mean Squared Error: 25824.864956727335\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=23, min_samples_leaf=6,\n",
      "                      min_samples_split=51)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=23, min_samples_leaf=6,\n",
      "                      min_samples_split=51)\n",
      "Test score R^2: 0.5747918915000031\n",
      "Train score R^2: 0.5747918915000031\n",
      "Mean Squared Error: 2583.733705594328\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=23, min_samples_leaf=6,\n",
      "                      min_samples_split=51)\n",
      "Test score R^2: 0.7423932765727297\n",
      "Train score R^2: 0.7423932765727297\n",
      "Mean Squared Error: 52637187092.92724\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.8, max_depth=9, min_samples_leaf=17,\n",
      "                      min_samples_split=33)\n",
      "Test score R^2: 0.8754858233234442\n",
      "Train score R^2: 0.8754858233234442\n",
      "Mean Squared Error: 15306.306148853106\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.8, max_depth=9, min_samples_leaf=17,\n",
      "                      min_samples_split=33)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.8, max_depth=9, min_samples_leaf=17,\n",
      "                      min_samples_split=33)\n",
      "Test score R^2: 0.5826937020887717\n",
      "Train score R^2: 0.5826937020887717\n",
      "Mean Squared Error: 2535.7191594337537\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.8, max_depth=9, min_samples_leaf=17,\n",
      "                      min_samples_split=33)\n",
      "Test score R^2: 0.6408598599072635\n",
      "Train score R^2: 0.6408598599072635\n",
      "Mean Squared Error: 73383669863.6425\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=11, min_samples_leaf=58,\n",
      "                      min_samples_split=36)\n",
      "Test score R^2: 0.6247132560729404\n",
      "Train score R^2: 0.6247132560729404\n",
      "Mean Squared Error: 46133.33155689871\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=11, min_samples_leaf=58,\n",
      "                      min_samples_split=36)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=11, min_samples_leaf=58,\n",
      "                      min_samples_split=36)\n",
      "Test score R^2: 0.43254023226744\n",
      "Train score R^2: 0.43254023226744\n",
      "Mean Squared Error: 3448.111405098839\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=11, min_samples_leaf=58,\n",
      "                      min_samples_split=36)\n",
      "Test score R^2: 0.48975175804838733\n",
      "Train score R^2: 0.48975175804838733\n",
      "Mean Squared Error: 104259826056.23653\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.8, max_depth=27, min_samples_leaf=60,\n",
      "                      min_samples_split=8)\n",
      "Test score R^2: 0.6121922981892298\n",
      "Train score R^2: 0.6121922981892298\n",
      "Mean Squared Error: 47672.51062678733\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.8, max_depth=27, min_samples_leaf=60,\n",
      "                      min_samples_split=8)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.8, max_depth=27, min_samples_leaf=60,\n",
      "                      min_samples_split=8)\n",
      "Test score R^2: 0.4325056218164366\n",
      "Train score R^2: 0.4325056218164366\n",
      "Mean Squared Error: 3448.3217119745445\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.8, max_depth=27, min_samples_leaf=60,\n",
      "                      min_samples_split=8)\n",
      "Test score R^2: 0.4859759704370552\n",
      "Train score R^2: 0.4859759704370552\n",
      "Mean Squared Error: 105031338679.34148\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=15, min_samples_leaf=29,\n",
      "                      min_samples_split=49)\n",
      "Test score R^2: 0.7815269691092457\n",
      "Train score R^2: 0.7815269691092457\n",
      "Mean Squared Error: 26856.500884781224\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=15, min_samples_leaf=29,\n",
      "                      min_samples_split=49)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=15, min_samples_leaf=29,\n",
      "                      min_samples_split=49)\n",
      "Test score R^2: 0.48146213781166225\n",
      "Train score R^2: 0.48146213781166225\n",
      "Mean Squared Error: 3150.8424354585054\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=15, min_samples_leaf=29,\n",
      "                      min_samples_split=49)\n",
      "Test score R^2: 0.545052442272614\n",
      "Train score R^2: 0.545052442272614\n",
      "Mean Squared Error: 92960150243.62392\n",
      "Parameter set: DecisionTreeRegressor(max_depth=4, min_samples_leaf=9, min_samples_split=52)\n",
      "Test score R^2: 0.789919150538415\n",
      "Train score R^2: 0.789919150538415\n",
      "Mean Squared Error: 25824.864956727335\n",
      "Parameter set: DecisionTreeRegressor(max_depth=4, min_samples_leaf=9, min_samples_split=52)\n",
      "Test score R^2: 0.19995404132780148\n",
      "Train score R^2: 0.19995404132780148\n",
      "Mean Squared Error: 8.980191880925494\n",
      "Parameter set: DecisionTreeRegressor(max_depth=4, min_samples_leaf=9, min_samples_split=52)\n",
      "Test score R^2: 0.5309684213168144\n",
      "Train score R^2: 0.5309684213168144\n",
      "Mean Squared Error: 2850.0225527375464\n",
      "Parameter set: DecisionTreeRegressor(max_depth=4, min_samples_leaf=9, min_samples_split=52)\n",
      "Test score R^2: 0.5628868854192738\n",
      "Train score R^2: 0.5628868854192738\n",
      "Mean Squared Error: 89316010416.3731\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=5,\n",
      "                      min_samples_leaf=30, min_samples_split=36)\n",
      "Test score R^2: 0.7815269691092457\n",
      "Train score R^2: 0.7815269691092457\n",
      "Mean Squared Error: 26856.500884781224\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=5,\n",
      "                      min_samples_leaf=30, min_samples_split=36)\n",
      "Test score R^2: 0.15528101406816253\n",
      "Train score R^2: 0.15528101406816253\n",
      "Mean Squared Error: 9.48162852008955\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=5,\n",
      "                      min_samples_leaf=30, min_samples_split=36)\n",
      "Test score R^2: 0.48146213781166225\n",
      "Train score R^2: 0.48146213781166225\n",
      "Mean Squared Error: 3150.8424354585054\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=5,\n",
      "                      min_samples_leaf=30, min_samples_split=36)\n",
      "Test score R^2: 0.5362524536474875\n",
      "Train score R^2: 0.5362524536474875\n",
      "Mean Squared Error: 94758265764.49924\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.8, max_depth=11, min_samples_leaf=27,\n",
      "                      min_samples_split=23)\n",
      "Test score R^2: 0.789919150538415\n",
      "Train score R^2: 0.789919150538415\n",
      "Mean Squared Error: 25824.864956727335\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.8, max_depth=11, min_samples_leaf=27,\n",
      "                      min_samples_split=23)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.8, max_depth=11, min_samples_leaf=27,\n",
      "                      min_samples_split=23)\n",
      "Test score R^2: 0.5213709259235062\n",
      "Train score R^2: 0.5213709259235062\n",
      "Mean Squared Error: 2908.3407546750736\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.8, max_depth=11, min_samples_leaf=27,\n",
      "                      min_samples_split=23)\n",
      "Test score R^2: 0.5504928637189375\n",
      "Train score R^2: 0.5504928637189375\n",
      "Mean Squared Error: 91848500370.03145\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.6000000000000001, max_depth=22,\n",
      "                      min_samples_leaf=38, min_samples_split=35)\n",
      "Test score R^2: 0.7751794365385887\n",
      "Train score R^2: 0.7751794365385887\n",
      "Mean Squared Error: 27636.79176739031\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.6000000000000001, max_depth=22,\n",
      "                      min_samples_leaf=38, min_samples_split=35)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.6000000000000001, max_depth=22,\n",
      "                      min_samples_leaf=38, min_samples_split=35)\n",
      "Test score R^2: 0.4794698155499745\n",
      "Train score R^2: 0.4794698155499745\n",
      "Mean Squared Error: 3162.94857849065\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.6000000000000001, max_depth=22,\n",
      "                      min_samples_leaf=38, min_samples_split=35)\n",
      "Test score R^2: 0.5296159165459413\n",
      "Train score R^2: 0.5296159165459413\n",
      "Mean Squared Error: 96114319831.78322\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=15, min_samples_leaf=19,\n",
      "                      min_samples_split=38)\n",
      "Test score R^2: 0.869414909705108\n",
      "Train score R^2: 0.869414909705108\n",
      "Mean Squared Error: 16052.59275593462\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=15, min_samples_leaf=19,\n",
      "                      min_samples_split=38)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=15, min_samples_leaf=19,\n",
      "                      min_samples_split=38)\n",
      "Test score R^2: 0.5763615414125599\n",
      "Train score R^2: 0.5763615414125599\n",
      "Mean Squared Error: 2574.195887984586\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=15, min_samples_leaf=19,\n",
      "                      min_samples_split=38)\n",
      "Test score R^2: 0.636653723903418\n",
      "Train score R^2: 0.636653723903418\n",
      "Mean Squared Error: 74243116250.86081\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=3,\n",
      "                      min_samples_leaf=25, min_samples_split=8)\n",
      "Test score R^2: 0.789919150538415\n",
      "Train score R^2: 0.789919150538415\n",
      "Mean Squared Error: 25824.864956727335\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=3,\n",
      "                      min_samples_leaf=25, min_samples_split=8)\n",
      "Test score R^2: 0.15528101406816253\n",
      "Train score R^2: 0.15528101406816253\n",
      "Mean Squared Error: 9.48162852008955\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=3,\n",
      "                      min_samples_leaf=25, min_samples_split=8)\n",
      "Test score R^2: 0.5016692662241489\n",
      "Train score R^2: 0.5016692662241489\n",
      "Mean Squared Error: 3028.055880524747\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=3,\n",
      "                      min_samples_leaf=25, min_samples_split=8)\n",
      "Test score R^2: 0.6095541668683361\n",
      "Train score R^2: 0.6095541668683361\n",
      "Mean Squared Error: 79780411375.82202\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=8, min_samples_leaf=46,\n",
      "                      min_samples_split=34)\n",
      "Test score R^2: 0.674980824248782\n",
      "Train score R^2: 0.674980824248782\n",
      "Mean Squared Error: 39954.028859050595\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=8, min_samples_leaf=46,\n",
      "                      min_samples_split=34)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=8, min_samples_leaf=46,\n",
      "                      min_samples_split=34)\n",
      "Test score R^2: 0.47017490278118934\n",
      "Train score R^2: 0.47017490278118934\n",
      "Mean Squared Error: 3219.4281679697615\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=8, min_samples_leaf=46,\n",
      "                      min_samples_split=34)\n",
      "Test score R^2: 0.5157035955123616\n",
      "Train score R^2: 0.5157035955123616\n",
      "Mean Squared Error: 98957046276.9575\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.6000000000000001, max_depth=20,\n",
      "                      min_samples_leaf=50, min_samples_split=25)\n",
      "Test score R^2: 0.6614608740257046\n",
      "Train score R^2: 0.6614608740257046\n",
      "Mean Squared Error: 41616.012279374176\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.6000000000000001, max_depth=20,\n",
      "                      min_samples_leaf=50, min_samples_split=25)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.6000000000000001, max_depth=20,\n",
      "                      min_samples_leaf=50, min_samples_split=25)\n",
      "Test score R^2: 0.44581064214699184\n",
      "Train score R^2: 0.44581064214699184\n",
      "Mean Squared Error: 3367.4751128752387\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.6000000000000001, max_depth=20,\n",
      "                      min_samples_leaf=50, min_samples_split=25)\n",
      "Test score R^2: 0.5157035955123616\n",
      "Train score R^2: 0.5157035955123616\n",
      "Mean Squared Error: 98957046276.9575\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=1, min_samples_leaf=31,\n",
      "                      min_samples_split=34)\n",
      "Test score R^2: 0.6950440400288784\n",
      "Train score R^2: 0.6950440400288784\n",
      "Mean Squared Error: 37487.69344843805\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=1, min_samples_leaf=31,\n",
      "                      min_samples_split=34)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=1, min_samples_leaf=31,\n",
      "                      min_samples_split=34)\n",
      "Test score R^2: 0.30430942765565605\n",
      "Train score R^2: 0.30430942765565605\n",
      "Mean Squared Error: 4227.292811445302\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=1, min_samples_leaf=31,\n",
      "                      min_samples_split=34)\n",
      "Test score R^2: 0.45902318512499396\n",
      "Train score R^2: 0.45902318512499396\n",
      "Mean Squared Error: 110538643707.22058\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=25, min_samples_leaf=43,\n",
      "                      min_samples_split=57)\n",
      "Test score R^2: 0.6757538978499069\n",
      "Train score R^2: 0.6757538978499069\n",
      "Mean Squared Error: 39858.99629705444\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=25, min_samples_leaf=43,\n",
      "                      min_samples_split=57)\n",
      "Test score R^2: 0.1809270356624959\n",
      "Train score R^2: 0.1809270356624959\n",
      "Mean Squared Error: 9.193762313900969\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=25, min_samples_leaf=43,\n",
      "                      min_samples_split=57)\n",
      "Test score R^2: 0.47574569176031156\n",
      "Train score R^2: 0.47574569176031156\n",
      "Mean Squared Error: 3185.5778368862666\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=25, min_samples_leaf=43,\n",
      "                      min_samples_split=57)\n",
      "Test score R^2: 0.5275820132686264\n",
      "Train score R^2: 0.5275820132686264\n",
      "Mean Squared Error: 96529910488.39572\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=16,\n",
      "                      min_samples_leaf=26, min_samples_split=6)\n",
      "Test score R^2: 0.789919150538415\n",
      "Train score R^2: 0.789919150538415\n",
      "Mean Squared Error: 25824.864956727335\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=16,\n",
      "                      min_samples_leaf=26, min_samples_split=6)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=16,\n",
      "                      min_samples_leaf=26, min_samples_split=6)\n",
      "Test score R^2: 0.5285725474396232\n",
      "Train score R^2: 0.5285725474396232\n",
      "Mean Squared Error: 2864.580836004272\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=16,\n",
      "                      min_samples_leaf=26, min_samples_split=6)\n",
      "Test score R^2: 0.550564359687072\n",
      "Train score R^2: 0.550564359687072\n",
      "Mean Squared Error: 91833891486.37726\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=28, min_samples_leaf=29,\n",
      "                      min_samples_split=19)\n",
      "Test score R^2: 0.7815269691092457\n",
      "Train score R^2: 0.7815269691092457\n",
      "Mean Squared Error: 26856.500884781224\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=28, min_samples_leaf=29,\n",
      "                      min_samples_split=19)\n",
      "Test score R^2: 0.20919115906260877\n",
      "Train score R^2: 0.20919115906260877\n",
      "Mean Squared Error: 8.87650897522975\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=28, min_samples_leaf=29,\n",
      "                      min_samples_split=19)\n",
      "Test score R^2: 0.48146213781166225\n",
      "Train score R^2: 0.48146213781166225\n",
      "Mean Squared Error: 3150.8424354585054\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=28, min_samples_leaf=29,\n",
      "                      min_samples_split=19)\n",
      "Test score R^2: 0.545052442272614\n",
      "Train score R^2: 0.545052442272614\n",
      "Mean Squared Error: 92960150243.62392\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=3,\n",
      "                      min_samples_leaf=15, min_samples_split=41)\n",
      "Test score R^2: 0.789919150538415\n",
      "Train score R^2: 0.789919150538415\n",
      "Mean Squared Error: 25824.864956727335\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=3,\n",
      "                      min_samples_leaf=15, min_samples_split=41)\n",
      "Test score R^2: 0.1806842825046534\n",
      "Train score R^2: 0.1806842825046534\n",
      "Mean Squared Error: 9.1964871197868\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=3,\n",
      "                      min_samples_leaf=15, min_samples_split=41)\n",
      "Test score R^2: 0.5052874236849989\n",
      "Train score R^2: 0.5052874236849989\n",
      "Mean Squared Error: 3006.0705157189727\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=3,\n",
      "                      min_samples_leaf=15, min_samples_split=41)\n",
      "Test score R^2: 0.635531468958431\n",
      "Train score R^2: 0.635531468958431\n",
      "Mean Squared Error: 74472428369.42403\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.6000000000000001, max_depth=24,\n",
      "                      min_samples_leaf=8, min_samples_split=47)\n",
      "Test score R^2: 0.789919150538415\n",
      "Train score R^2: 0.789919150538415\n",
      "Mean Squared Error: 25824.864956727335\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.6000000000000001, max_depth=24,\n",
      "                      min_samples_leaf=8, min_samples_split=47)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.6000000000000001, max_depth=24,\n",
      "                      min_samples_leaf=8, min_samples_split=47)\n",
      "Test score R^2: 0.5806535453813877\n",
      "Train score R^2: 0.5806535453813877\n",
      "Mean Squared Error: 2548.1159635966787\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.6000000000000001, max_depth=24,\n",
      "                      min_samples_leaf=8, min_samples_split=47)\n",
      "Test score R^2: 0.7132709369960079\n",
      "Train score R^2: 0.7132709369960079\n",
      "Mean Squared Error: 58587800557.08415\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=7, min_samples_leaf=41,\n",
      "                      min_samples_split=43)\n",
      "Test score R^2: 0.7402081258787053\n",
      "Train score R^2: 0.7402081258787053\n",
      "Mean Squared Error: 31935.752750582593\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=7, min_samples_leaf=41,\n",
      "                      min_samples_split=43)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=7, min_samples_leaf=41,\n",
      "                      min_samples_split=43)\n",
      "Test score R^2: 0.4794068998364953\n",
      "Train score R^2: 0.4794068998364953\n",
      "Mean Squared Error: 3163.330879407021\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=7, min_samples_leaf=41,\n",
      "                      min_samples_split=43)\n",
      "Test score R^2: 0.5277948215835083\n",
      "Train score R^2: 0.5277948215835083\n",
      "Mean Squared Error: 96486427030.60265\n",
      "Parameter set: DecisionTreeRegressor(max_depth=26, min_samples_leaf=43, min_samples_split=45)\n",
      "Test score R^2: 0.6757538978499069\n",
      "Train score R^2: 0.6757538978499069\n",
      "Mean Squared Error: 39858.99629705444\n",
      "Parameter set: DecisionTreeRegressor(max_depth=26, min_samples_leaf=43, min_samples_split=45)\n",
      "Test score R^2: 0.1809270356624959\n",
      "Train score R^2: 0.1809270356624959\n",
      "Mean Squared Error: 9.193762313900969\n",
      "Parameter set: DecisionTreeRegressor(max_depth=26, min_samples_leaf=43, min_samples_split=45)\n",
      "Test score R^2: 0.47574569176031156\n",
      "Train score R^2: 0.47574569176031156\n",
      "Mean Squared Error: 3185.5778368862666\n",
      "Parameter set: DecisionTreeRegressor(max_depth=26, min_samples_leaf=43, min_samples_split=45)\n",
      "Test score R^2: 0.5275820132686264\n",
      "Train score R^2: 0.5275820132686264\n",
      "Mean Squared Error: 96529910488.39572\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.9, max_depth=3, min_samples_leaf=4,\n",
      "                      min_samples_split=12)\n",
      "Test score R^2: 0.9414024724097059\n",
      "Train score R^2: 0.9414024724097059\n",
      "Mean Squared Error: 7203.289784365447\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.9, max_depth=3, min_samples_leaf=4,\n",
      "                      min_samples_split=12)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.9, max_depth=3, min_samples_leaf=4,\n",
      "                      min_samples_split=12)\n",
      "Test score R^2: 0.5165660615225274\n",
      "Train score R^2: 0.5165660615225274\n",
      "Mean Squared Error: 2937.5370231738416\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.9, max_depth=3, min_samples_leaf=4,\n",
      "                      min_samples_split=12)\n",
      "Test score R^2: 0.7618228716715465\n",
      "Train score R^2: 0.7618228716715465\n",
      "Mean Squared Error: 48667107357.62488\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=18, min_samples_leaf=32,\n",
      "                      min_samples_split=41)\n",
      "Test score R^2: 0.7815269691092457\n",
      "Train score R^2: 0.7815269691092457\n",
      "Mean Squared Error: 26856.500884781224\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=18, min_samples_leaf=32,\n",
      "                      min_samples_split=41)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=18, min_samples_leaf=32,\n",
      "                      min_samples_split=41)\n",
      "Test score R^2: 0.480156371378637\n",
      "Train score R^2: 0.480156371378637\n",
      "Mean Squared Error: 3158.7767920175625\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=18, min_samples_leaf=32,\n",
      "                      min_samples_split=41)\n",
      "Test score R^2: 0.5342717500249307\n",
      "Train score R^2: 0.5342717500249307\n",
      "Mean Squared Error: 95162986051.95558\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=14, min_samples_leaf=60,\n",
      "                      min_samples_split=57)\n",
      "Test score R^2: 0.6121922981892298\n",
      "Train score R^2: 0.6121922981892298\n",
      "Mean Squared Error: 47672.51062678733\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=14, min_samples_leaf=60,\n",
      "                      min_samples_split=57)\n",
      "Test score R^2: 0.14250945833885176\n",
      "Train score R^2: 0.14250945833885176\n",
      "Mean Squared Error: 9.624984060885597\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=14, min_samples_leaf=60,\n",
      "                      min_samples_split=57)\n",
      "Test score R^2: 0.4325056218164366\n",
      "Train score R^2: 0.4325056218164366\n",
      "Mean Squared Error: 3448.3217119745445\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=14, min_samples_leaf=60,\n",
      "                      min_samples_split=57)\n",
      "Test score R^2: 0.4859759704370552\n",
      "Train score R^2: 0.4859759704370552\n",
      "Mean Squared Error: 105031338679.34148\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=15,\n",
      "                      min_samples_leaf=45, min_samples_split=16)\n",
      "Test score R^2: 0.674980824248782\n",
      "Train score R^2: 0.674980824248782\n",
      "Mean Squared Error: 39954.028859050595\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=15,\n",
      "                      min_samples_leaf=45, min_samples_split=16)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=15,\n",
      "                      min_samples_leaf=45, min_samples_split=16)\n",
      "Test score R^2: 0.47574569176031156\n",
      "Train score R^2: 0.47574569176031156\n",
      "Mean Squared Error: 3185.5778368862666\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=15,\n",
      "                      min_samples_leaf=45, min_samples_split=16)\n",
      "Test score R^2: 0.5157035955123616\n",
      "Train score R^2: 0.5157035955123616\n",
      "Mean Squared Error: 98957046276.9575\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=17, min_samples_leaf=16,\n",
      "                      min_samples_split=42)\n",
      "Test score R^2: 0.789919150538415\n",
      "Train score R^2: 0.789919150538415\n",
      "Mean Squared Error: 25824.864956727335\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=17, min_samples_leaf=16,\n",
      "                      min_samples_split=42)\n",
      "Test score R^2: 0.2176460180142843\n",
      "Train score R^2: 0.2176460180142843\n",
      "Mean Squared Error: 8.781606607573\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=17, min_samples_leaf=16,\n",
      "                      min_samples_split=42)\n",
      "Test score R^2: 0.5537554423898683\n",
      "Train score R^2: 0.5537554423898683\n",
      "Mean Squared Error: 2711.559543167403\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=17, min_samples_leaf=16,\n",
      "                      min_samples_split=42)\n",
      "Test score R^2: 0.6546960075143446\n",
      "Train score R^2: 0.6546960075143446\n",
      "Mean Squared Error: 70556508054.54901\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=28, min_samples_leaf=14,\n",
      "                      min_samples_split=4)\n",
      "Test score R^2: 0.8947706618429201\n",
      "Train score R^2: 0.8947706618429201\n",
      "Mean Squared Error: 12935.655269659916\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=28, min_samples_leaf=14,\n",
      "                      min_samples_split=4)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=28, min_samples_leaf=14,\n",
      "                      min_samples_split=4)\n",
      "Test score R^2: 0.5937841883182893\n",
      "Train score R^2: 0.5937841883182893\n",
      "Mean Squared Error: 2468.32895094568\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=28, min_samples_leaf=14,\n",
      "                      min_samples_split=4)\n",
      "Test score R^2: 0.7259707906107917\n",
      "Train score R^2: 0.7259707906107917\n",
      "Mean Squared Error: 55992819487.17859\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=24, min_samples_leaf=20,\n",
      "                      min_samples_split=42)\n",
      "Test score R^2: 0.789919150538415\n",
      "Train score R^2: 0.789919150538415\n",
      "Mean Squared Error: 25824.864956727335\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=24, min_samples_leaf=20,\n",
      "                      min_samples_split=42)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=24, min_samples_leaf=20,\n",
      "                      min_samples_split=42)\n",
      "Test score R^2: 0.5536038381089772\n",
      "Train score R^2: 0.5536038381089772\n",
      "Mean Squared Error: 2712.48075111857\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=24, min_samples_leaf=20,\n",
      "                      min_samples_split=42)\n",
      "Test score R^2: 0.6353815059005299\n",
      "Train score R^2: 0.6353815059005299\n",
      "Mean Squared Error: 74503070556.98326\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=5,\n",
      "                      min_samples_leaf=4, min_samples_split=16)\n",
      "Test score R^2: 0.9625023953085706\n",
      "Train score R^2: 0.9625023953085706\n",
      "Mean Squared Error: 4609.513812604719\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=5,\n",
      "                      min_samples_leaf=4, min_samples_split=16)\n",
      "Test score R^2: 0.1806842825046534\n",
      "Train score R^2: 0.1806842825046534\n",
      "Mean Squared Error: 9.1964871197868\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=5,\n",
      "                      min_samples_leaf=4, min_samples_split=16)\n",
      "Test score R^2: 0.6311648302123346\n",
      "Train score R^2: 0.6311648302123346\n",
      "Mean Squared Error: 2241.189292816613\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=5,\n",
      "                      min_samples_leaf=4, min_samples_split=16)\n",
      "Test score R^2: 0.8097001117140348\n",
      "Train score R^2: 0.8097001117140348\n",
      "Mean Squared Error: 38884275574.040054\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=24,\n",
      "                      min_samples_leaf=59, min_samples_split=55)\n",
      "Test score R^2: 0.6191250374142274\n",
      "Train score R^2: 0.6191250374142274\n",
      "Mean Squared Error: 46820.28133161539\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=24,\n",
      "                      min_samples_leaf=59, min_samples_split=55)\n",
      "Test score R^2: 0.14250945833885176\n",
      "Train score R^2: 0.14250945833885176\n",
      "Mean Squared Error: 9.624984060885597\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=24,\n",
      "                      min_samples_leaf=59, min_samples_split=55)\n",
      "Test score R^2: 0.43254023226744\n",
      "Train score R^2: 0.43254023226744\n",
      "Mean Squared Error: 3448.111405098839\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=24,\n",
      "                      min_samples_leaf=59, min_samples_split=55)\n",
      "Test score R^2: 0.4859759704370552\n",
      "Train score R^2: 0.4859759704370552\n",
      "Mean Squared Error: 105031338679.34148\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=12, min_samples_leaf=8,\n",
      "                      min_samples_split=14)\n",
      "Test score R^2: 0.9131382602638092\n",
      "Train score R^2: 0.9131382602638092\n",
      "Mean Squared Error: 10677.759083431878\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=12, min_samples_leaf=8,\n",
      "                      min_samples_split=14)\n",
      "Test score R^2: 0.3885460744978132\n",
      "Train score R^2: 0.3885460744978132\n",
      "Mean Squared Error: 6.863322685196597\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=12, min_samples_leaf=8,\n",
      "                      min_samples_split=14)\n",
      "Test score R^2: 0.6924334582532494\n",
      "Train score R^2: 0.6924334582532494\n",
      "Mean Squared Error: 1868.8967231305048\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=12, min_samples_leaf=8,\n",
      "                      min_samples_split=14)\n",
      "Test score R^2: 0.7467842643674345\n",
      "Train score R^2: 0.7467842643674345\n",
      "Mean Squared Error: 51739969648.45359\n",
      "Parameter set: DecisionTreeRegressor(max_depth=28, min_samples_leaf=41, min_samples_split=10)\n",
      "Test score R^2: 0.7402081258787053\n",
      "Train score R^2: 0.7402081258787053\n",
      "Mean Squared Error: 31935.752750582593\n",
      "Parameter set: DecisionTreeRegressor(max_depth=28, min_samples_leaf=41, min_samples_split=10)\n",
      "Test score R^2: 0.19708791993451302\n",
      "Train score R^2: 0.19708791993451302\n",
      "Mean Squared Error: 9.01236293283415\n",
      "Parameter set: DecisionTreeRegressor(max_depth=28, min_samples_leaf=41, min_samples_split=10)\n",
      "Test score R^2: 0.4794068998364953\n",
      "Train score R^2: 0.4794068998364953\n",
      "Mean Squared Error: 3163.330879407021\n",
      "Parameter set: DecisionTreeRegressor(max_depth=28, min_samples_leaf=41, min_samples_split=10)\n",
      "Test score R^2: 0.5277948215835083\n",
      "Train score R^2: 0.5277948215835083\n",
      "Mean Squared Error: 96486427030.60265\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=16, min_samples_leaf=38)\n",
      "Test score R^2: 0.7751794365385887\n",
      "Train score R^2: 0.7751794365385887\n",
      "Mean Squared Error: 27636.79176739031\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=16, min_samples_leaf=38)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=16, min_samples_leaf=38)\n",
      "Test score R^2: 0.4794698155499745\n",
      "Train score R^2: 0.4794698155499745\n",
      "Mean Squared Error: 3162.94857849065\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=16, min_samples_leaf=38)\n",
      "Test score R^2: 0.5296159165459413\n",
      "Train score R^2: 0.5296159165459413\n",
      "Mean Squared Error: 96114319831.78322\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=22, min_samples_leaf=51,\n",
      "                      min_samples_split=27)\n",
      "Test score R^2: 0.6520724875020846\n",
      "Train score R^2: 0.6520724875020846\n",
      "Mean Squared Error: 42770.10992680578\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=22, min_samples_leaf=51,\n",
      "                      min_samples_split=27)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=22, min_samples_leaf=51,\n",
      "                      min_samples_split=27)\n",
      "Test score R^2: 0.43684482413295955\n",
      "Train score R^2: 0.43684482413295955\n",
      "Mean Squared Error: 3421.9549916404862\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=22, min_samples_leaf=51,\n",
      "                      min_samples_split=27)\n",
      "Test score R^2: 0.5157035955123616\n",
      "Train score R^2: 0.5157035955123616\n",
      "Mean Squared Error: 98957046276.9575\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=18, min_samples_leaf=56,\n",
      "                      min_samples_split=17)\n",
      "Test score R^2: 0.6398645148605644\n",
      "Train score R^2: 0.6398645148605644\n",
      "Mean Squared Error: 44270.814277871956\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=18, min_samples_leaf=56,\n",
      "                      min_samples_split=17)\n",
      "Test score R^2: 0.1534043510128621\n",
      "Train score R^2: 0.1534043510128621\n",
      "Mean Squared Error: 9.502693302868295\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=18, min_samples_leaf=56,\n",
      "                      min_samples_split=17)\n",
      "Test score R^2: 0.43684482413295955\n",
      "Train score R^2: 0.43684482413295955\n",
      "Mean Squared Error: 3421.9549916404862\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=18, min_samples_leaf=56,\n",
      "                      min_samples_split=17)\n",
      "Test score R^2: 0.4931640505110051\n",
      "Train score R^2: 0.4931640505110051\n",
      "Mean Squared Error: 103562586968.75864\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=18, min_samples_leaf=38,\n",
      "                      min_samples_split=55)\n",
      "Test score R^2: 0.7751794365385887\n",
      "Train score R^2: 0.7751794365385887\n",
      "Mean Squared Error: 27636.79176739031\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=18, min_samples_leaf=38,\n",
      "                      min_samples_split=55)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=18, min_samples_leaf=38,\n",
      "                      min_samples_split=55)\n",
      "Test score R^2: 0.4794698155499745\n",
      "Train score R^2: 0.4794698155499745\n",
      "Mean Squared Error: 3162.94857849065\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=18, min_samples_leaf=38,\n",
      "                      min_samples_split=55)\n",
      "Test score R^2: 0.5296159165459413\n",
      "Train score R^2: 0.5296159165459413\n",
      "Mean Squared Error: 96114319831.78322\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=30, min_samples_leaf=16,\n",
      "                      min_samples_split=51)\n",
      "Test score R^2: 0.789919150538415\n",
      "Train score R^2: 0.789919150538415\n",
      "Mean Squared Error: 25824.864956727335\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=30, min_samples_leaf=16,\n",
      "                      min_samples_split=51)\n",
      "Test score R^2: 0.2176460180142843\n",
      "Train score R^2: 0.2176460180142843\n",
      "Mean Squared Error: 8.781606607573\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=30, min_samples_leaf=16,\n",
      "                      min_samples_split=51)\n",
      "Test score R^2: 0.5344839302302796\n",
      "Train score R^2: 0.5344839302302796\n",
      "Mean Squared Error: 2828.6609213611364\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=30, min_samples_leaf=16,\n",
      "                      min_samples_split=51)\n",
      "Test score R^2: 0.6546960075143446\n",
      "Train score R^2: 0.6546960075143446\n",
      "Mean Squared Error: 70556508054.54901\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=16,\n",
      "                      min_samples_leaf=23, min_samples_split=13)\n",
      "Test score R^2: 0.789919150538415\n",
      "Train score R^2: 0.789919150538415\n",
      "Mean Squared Error: 25824.864956727335\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=16,\n",
      "                      min_samples_leaf=23, min_samples_split=13)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=16,\n",
      "                      min_samples_leaf=23, min_samples_split=13)\n",
      "Test score R^2: 0.5341648577689877\n",
      "Train score R^2: 0.5341648577689877\n",
      "Mean Squared Error: 2830.599732630929\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=16,\n",
      "                      min_samples_leaf=23, min_samples_split=13)\n",
      "Test score R^2: 0.6221695059002976\n",
      "Train score R^2: 0.6221695059002976\n",
      "Mean Squared Error: 77202699303.59212\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=15, min_samples_leaf=53,\n",
      "                      min_samples_split=41)\n",
      "Test score R^2: 0.6441798202604005\n",
      "Train score R^2: 0.6441798202604005\n",
      "Mean Squared Error: 43740.34146474588\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=15, min_samples_leaf=53,\n",
      "                      min_samples_split=41)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=15, min_samples_leaf=53,\n",
      "                      min_samples_split=41)\n",
      "Test score R^2: 0.43684482413295955\n",
      "Train score R^2: 0.43684482413295955\n",
      "Mean Squared Error: 3421.9549916404862\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=15, min_samples_leaf=53,\n",
      "                      min_samples_split=41)\n",
      "Test score R^2: 0.4931640505110051\n",
      "Train score R^2: 0.4931640505110051\n",
      "Mean Squared Error: 103562586968.75864\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.8, max_depth=29, min_samples_leaf=51,\n",
      "                      min_samples_split=37)\n",
      "Test score R^2: 0.6520724875020846\n",
      "Train score R^2: 0.6520724875020846\n",
      "Mean Squared Error: 42770.10992680578\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.8, max_depth=29, min_samples_leaf=51,\n",
      "                      min_samples_split=37)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.8, max_depth=29, min_samples_leaf=51,\n",
      "                      min_samples_split=37)\n",
      "Test score R^2: 0.43684482413295955\n",
      "Train score R^2: 0.43684482413295955\n",
      "Mean Squared Error: 3421.9549916404862\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.8, max_depth=29, min_samples_leaf=51,\n",
      "                      min_samples_split=37)\n",
      "Test score R^2: 0.5157035955123616\n",
      "Train score R^2: 0.5157035955123616\n",
      "Mean Squared Error: 98957046276.9575\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=7,\n",
      "                      min_samples_leaf=49, min_samples_split=9)\n",
      "Test score R^2: 0.674980824248782\n",
      "Train score R^2: 0.674980824248782\n",
      "Mean Squared Error: 39954.028859050595\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=7,\n",
      "                      min_samples_leaf=49, min_samples_split=9)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=7,\n",
      "                      min_samples_leaf=49, min_samples_split=9)\n",
      "Test score R^2: 0.45216237122574277\n",
      "Train score R^2: 0.45216237122574277\n",
      "Mean Squared Error: 3328.8794789221\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=7,\n",
      "                      min_samples_leaf=49, min_samples_split=9)\n",
      "Test score R^2: 0.5157035955123616\n",
      "Train score R^2: 0.5157035955123616\n",
      "Mean Squared Error: 98957046276.9575\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=7,\n",
      "                      min_samples_leaf=11, min_samples_split=23)\n",
      "Test score R^2: 0.9073492153965822\n",
      "Train score R^2: 0.9073492153965822\n",
      "Mean Squared Error: 11389.396066563511\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=7,\n",
      "                      min_samples_leaf=11, min_samples_split=23)\n",
      "Test score R^2: 0.22179053685944383\n",
      "Train score R^2: 0.22179053685944383\n",
      "Mean Squared Error: 8.735086061996576\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=7,\n",
      "                      min_samples_leaf=11, min_samples_split=23)\n",
      "Test score R^2: 0.6209040632724161\n",
      "Train score R^2: 0.6209040632724161\n",
      "Mean Squared Error: 2303.537796662032\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=7,\n",
      "                      min_samples_leaf=11, min_samples_split=23)\n",
      "Test score R^2: 0.7353659834166489\n",
      "Train score R^2: 0.7353659834166489\n",
      "Mean Squared Error: 54073084959.61432\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=10,\n",
      "                      min_samples_leaf=46, min_samples_split=19)\n",
      "Test score R^2: 0.674980824248782\n",
      "Train score R^2: 0.674980824248782\n",
      "Mean Squared Error: 39954.028859050595\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=10,\n",
      "                      min_samples_leaf=46, min_samples_split=19)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=10,\n",
      "                      min_samples_leaf=46, min_samples_split=19)\n",
      "Test score R^2: 0.47017490278118934\n",
      "Train score R^2: 0.47017490278118934\n",
      "Mean Squared Error: 3219.4281679697615\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=10,\n",
      "                      min_samples_leaf=46, min_samples_split=19)\n",
      "Test score R^2: 0.5157035955123616\n",
      "Train score R^2: 0.5157035955123616\n",
      "Mean Squared Error: 98957046276.9575\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=1,\n",
      "                      min_samples_leaf=37, min_samples_split=29)\n",
      "Test score R^2: 0.6950440400288784\n",
      "Train score R^2: 0.6950440400288784\n",
      "Mean Squared Error: 37487.69344843805\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=1,\n",
      "                      min_samples_leaf=37, min_samples_split=29)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=1,\n",
      "                      min_samples_leaf=37, min_samples_split=29)\n",
      "Test score R^2: 0.30430942765565605\n",
      "Train score R^2: 0.30430942765565605\n",
      "Mean Squared Error: 4227.292811445302\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=1,\n",
      "                      min_samples_leaf=37, min_samples_split=29)\n",
      "Test score R^2: 0.45902318512499396\n",
      "Train score R^2: 0.45902318512499396\n",
      "Mean Squared Error: 110538643707.22058\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=5, min_samples_leaf=49,\n",
      "                      min_samples_split=8)\n",
      "Test score R^2: 0.674980824248782\n",
      "Train score R^2: 0.674980824248782\n",
      "Mean Squared Error: 39954.028859050595\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=5, min_samples_leaf=49,\n",
      "                      min_samples_split=8)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=5, min_samples_leaf=49,\n",
      "                      min_samples_split=8)\n",
      "Test score R^2: 0.45216237122574277\n",
      "Train score R^2: 0.45216237122574277\n",
      "Mean Squared Error: 3328.8794789221\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=5, min_samples_leaf=49,\n",
      "                      min_samples_split=8)\n",
      "Test score R^2: 0.5157035955123616\n",
      "Train score R^2: 0.5157035955123616\n",
      "Mean Squared Error: 98957046276.9575\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=9, min_samples_leaf=34,\n",
      "                      min_samples_split=11)\n",
      "Test score R^2: 0.7792160901790647\n",
      "Train score R^2: 0.7792160901790647\n",
      "Mean Squared Error: 27140.573119143468\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=9, min_samples_leaf=34,\n",
      "                      min_samples_split=11)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=9, min_samples_leaf=34,\n",
      "                      min_samples_split=11)\n",
      "Test score R^2: 0.4794698155499745\n",
      "Train score R^2: 0.4794698155499745\n",
      "Mean Squared Error: 3162.94857849065\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=9, min_samples_leaf=34,\n",
      "                      min_samples_split=11)\n",
      "Test score R^2: 0.5310127455814226\n",
      "Train score R^2: 0.5310127455814226\n",
      "Mean Squared Error: 95828903557.31932\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=13, min_samples_leaf=42,\n",
      "                      min_samples_split=19)\n",
      "Test score R^2: 0.7390630088879218\n",
      "Train score R^2: 0.7390630088879218\n",
      "Mean Squared Error: 32076.51994436742\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=13, min_samples_leaf=42,\n",
      "                      min_samples_split=19)\n",
      "Test score R^2: 0.1809270356624959\n",
      "Train score R^2: 0.1809270356624959\n",
      "Mean Squared Error: 9.193762313900969\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=13, min_samples_leaf=42,\n",
      "                      min_samples_split=19)\n",
      "Test score R^2: 0.476473514519019\n",
      "Train score R^2: 0.476473514519019\n",
      "Mean Squared Error: 3181.155296121452\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=13, min_samples_leaf=42,\n",
      "                      min_samples_split=19)\n",
      "Test score R^2: 0.5275820132686264\n",
      "Train score R^2: 0.5275820132686264\n",
      "Mean Squared Error: 96529910488.39572\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=12,\n",
      "                      min_samples_leaf=44, min_samples_split=24)\n",
      "Test score R^2: 0.674980824248782\n",
      "Train score R^2: 0.674980824248782\n",
      "Mean Squared Error: 39954.028859050595\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=12,\n",
      "                      min_samples_leaf=44, min_samples_split=24)\n",
      "Test score R^2: 0.14250945833885176\n",
      "Train score R^2: 0.14250945833885176\n",
      "Mean Squared Error: 9.624984060885597\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=12,\n",
      "                      min_samples_leaf=44, min_samples_split=24)\n",
      "Test score R^2: 0.47574569176031156\n",
      "Train score R^2: 0.47574569176031156\n",
      "Mean Squared Error: 3185.5778368862666\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=12,\n",
      "                      min_samples_leaf=44, min_samples_split=24)\n",
      "Test score R^2: 0.5253118659699338\n",
      "Train score R^2: 0.5253118659699338\n",
      "Mean Squared Error: 96993773257.58125\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=17, min_samples_leaf=33,\n",
      "                      min_samples_split=27)\n",
      "Test score R^2: 0.7796770079594444\n",
      "Train score R^2: 0.7796770079594444\n",
      "Mean Squared Error: 27083.913316667586\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=17, min_samples_leaf=33,\n",
      "                      min_samples_split=27)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=17, min_samples_leaf=33,\n",
      "                      min_samples_split=27)\n",
      "Test score R^2: 0.4794698155499745\n",
      "Train score R^2: 0.4794698155499745\n",
      "Mean Squared Error: 3162.94857849065\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=17, min_samples_leaf=33,\n",
      "                      min_samples_split=27)\n",
      "Test score R^2: 0.5310127455814226\n",
      "Train score R^2: 0.5310127455814226\n",
      "Mean Squared Error: 95828903557.31932\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=26, min_samples_leaf=46,\n",
      "                      min_samples_split=3)\n",
      "Test score R^2: 0.674980824248782\n",
      "Train score R^2: 0.674980824248782\n",
      "Mean Squared Error: 39954.028859050595\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=26, min_samples_leaf=46,\n",
      "                      min_samples_split=3)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=26, min_samples_leaf=46,\n",
      "                      min_samples_split=3)\n",
      "Test score R^2: 0.47017490278118934\n",
      "Train score R^2: 0.47017490278118934\n",
      "Mean Squared Error: 3219.4281679697615\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=26, min_samples_leaf=46,\n",
      "                      min_samples_split=3)\n",
      "Test score R^2: 0.5157035955123616\n",
      "Train score R^2: 0.5157035955123616\n",
      "Mean Squared Error: 98957046276.9575\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=7,\n",
      "                      min_samples_leaf=20, min_samples_split=49)\n",
      "Test score R^2: 0.789919150538415\n",
      "Train score R^2: 0.789919150538415\n",
      "Mean Squared Error: 25824.864956727335\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=7,\n",
      "                      min_samples_leaf=20, min_samples_split=49)\n",
      "Test score R^2: 0.15528101406816253\n",
      "Train score R^2: 0.15528101406816253\n",
      "Mean Squared Error: 9.48162852008955\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=7,\n",
      "                      min_samples_leaf=20, min_samples_split=49)\n",
      "Test score R^2: 0.5392129080922491\n",
      "Train score R^2: 0.5392129080922491\n",
      "Mean Squared Error: 2799.925769677217\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.30000000000000004, max_depth=7,\n",
      "                      min_samples_leaf=20, min_samples_split=49)\n",
      "Test score R^2: 0.6353815059005299\n",
      "Train score R^2: 0.6353815059005299\n",
      "Mean Squared Error: 74503070556.98326\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.9, max_depth=4, min_samples_leaf=10,\n",
      "                      min_samples_split=52)\n",
      "Test score R^2: 0.789919150538415\n",
      "Train score R^2: 0.789919150538415\n",
      "Mean Squared Error: 25824.864956727335\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.9, max_depth=4, min_samples_leaf=10,\n",
      "                      min_samples_split=52)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.9, max_depth=4, min_samples_leaf=10,\n",
      "                      min_samples_split=52)\n",
      "Test score R^2: 0.5309684213168144\n",
      "Train score R^2: 0.5309684213168144\n",
      "Mean Squared Error: 2850.0225527375464\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.9, max_depth=4, min_samples_leaf=10,\n",
      "                      min_samples_split=52)\n",
      "Test score R^2: 0.5628868854192738\n",
      "Train score R^2: 0.5628868854192738\n",
      "Mean Squared Error: 89316010416.3731\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=15,\n",
      "                      min_samples_leaf=56, min_samples_split=48)\n",
      "Test score R^2: 0.6398645148605644\n",
      "Train score R^2: 0.6398645148605644\n",
      "Mean Squared Error: 44270.814277871956\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=15,\n",
      "                      min_samples_leaf=56, min_samples_split=48)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=15,\n",
      "                      min_samples_leaf=56, min_samples_split=48)\n",
      "Test score R^2: 0.43684482413295955\n",
      "Train score R^2: 0.43684482413295955\n",
      "Mean Squared Error: 3421.9549916404862\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=15,\n",
      "                      min_samples_leaf=56, min_samples_split=48)\n",
      "Test score R^2: 0.4931640505110051\n",
      "Train score R^2: 0.4931640505110051\n",
      "Mean Squared Error: 103562586968.75864\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=10, min_samples_leaf=22,\n",
      "                      min_samples_split=56)\n",
      "Test score R^2: 0.789919150538415\n",
      "Train score R^2: 0.789919150538415\n",
      "Mean Squared Error: 25824.864956727335\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=10, min_samples_leaf=22,\n",
      "                      min_samples_split=56)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=10, min_samples_leaf=22,\n",
      "                      min_samples_split=56)\n",
      "Test score R^2: 0.5302874867772754\n",
      "Train score R^2: 0.5302874867772754\n",
      "Mean Squared Error: 2854.1601820205733\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=10, min_samples_leaf=22,\n",
      "                      min_samples_split=56)\n",
      "Test score R^2: 0.5601988094452651\n",
      "Train score R^2: 0.5601988094452651\n",
      "Mean Squared Error: 89865269209.317\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=30, min_samples_leaf=49,\n",
      "                      min_samples_split=57)\n",
      "Test score R^2: 0.674980824248782\n",
      "Train score R^2: 0.674980824248782\n",
      "Mean Squared Error: 39954.028859050595\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=30, min_samples_leaf=49,\n",
      "                      min_samples_split=57)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=30, min_samples_leaf=49,\n",
      "                      min_samples_split=57)\n",
      "Test score R^2: 0.45216237122574277\n",
      "Train score R^2: 0.45216237122574277\n",
      "Mean Squared Error: 3328.8794789221\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=30, min_samples_leaf=49,\n",
      "                      min_samples_split=57)\n",
      "Test score R^2: 0.5157035955123616\n",
      "Train score R^2: 0.5157035955123616\n",
      "Mean Squared Error: 98957046276.9575\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=11, min_samples_leaf=7,\n",
      "                      min_samples_split=8)\n",
      "Test score R^2: 0.9306793607000595\n",
      "Train score R^2: 0.9306793607000595\n",
      "Mean Squared Error: 8521.462823589358\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=11, min_samples_leaf=7,\n",
      "                      min_samples_split=8)\n",
      "Test score R^2: 0.3165166769308815\n",
      "Train score R^2: 0.3165166769308815\n",
      "Mean Squared Error: 7.6718235021897145\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=11, min_samples_leaf=7,\n",
      "                      min_samples_split=8)\n",
      "Test score R^2: 0.712698625797633\n",
      "Train score R^2: 0.712698625797633\n",
      "Mean Squared Error: 1745.7574993310122\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=11, min_samples_leaf=7,\n",
      "                      min_samples_split=8)\n",
      "Test score R^2: 0.7866458847373039\n",
      "Train score R^2: 0.7866458847373039\n",
      "Mean Squared Error: 43594982043.62333\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.6000000000000001, max_depth=13,\n",
      "                      min_samples_leaf=31, min_samples_split=8)\n",
      "Test score R^2: 0.7815269691092457\n",
      "Train score R^2: 0.7815269691092457\n",
      "Mean Squared Error: 26856.500884781224\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.6000000000000001, max_depth=13,\n",
      "                      min_samples_leaf=31, min_samples_split=8)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.6000000000000001, max_depth=13,\n",
      "                      min_samples_leaf=31, min_samples_split=8)\n",
      "Test score R^2: 0.48146213781166225\n",
      "Train score R^2: 0.48146213781166225\n",
      "Mean Squared Error: 3150.8424354585054\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.6000000000000001, max_depth=13,\n",
      "                      min_samples_leaf=31, min_samples_split=8)\n",
      "Test score R^2: 0.5344809259917465\n",
      "Train score R^2: 0.5344809259917465\n",
      "Mean Squared Error: 95120244797.55763\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=4, min_samples_leaf=11,\n",
      "                      min_samples_split=10)\n",
      "Test score R^2: 0.9073492153965822\n",
      "Train score R^2: 0.9073492153965822\n",
      "Mean Squared Error: 11389.396066563511\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=4, min_samples_leaf=11,\n",
      "                      min_samples_split=10)\n",
      "Test score R^2: 0.2776782406428592\n",
      "Train score R^2: 0.2776782406428592\n",
      "Mean Squared Error: 8.107769220608679\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=4, min_samples_leaf=11,\n",
      "                      min_samples_split=10)\n",
      "Test score R^2: 0.5568749654147122\n",
      "Train score R^2: 0.5568749654147122\n",
      "Mean Squared Error: 2692.604079657782\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=4, min_samples_leaf=11,\n",
      "                      min_samples_split=10)\n",
      "Test score R^2: 0.7317986540268149\n",
      "Train score R^2: 0.7317986540268149\n",
      "Mean Squared Error: 54802002986.35131\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=16, min_samples_leaf=49,\n",
      "                      min_samples_split=42)\n",
      "Test score R^2: 0.674980824248782\n",
      "Train score R^2: 0.674980824248782\n",
      "Mean Squared Error: 39954.028859050595\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=16, min_samples_leaf=49,\n",
      "                      min_samples_split=42)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=16, min_samples_leaf=49,\n",
      "                      min_samples_split=42)\n",
      "Test score R^2: 0.45216237122574277\n",
      "Train score R^2: 0.45216237122574277\n",
      "Mean Squared Error: 3328.8794789221\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=16, min_samples_leaf=49,\n",
      "                      min_samples_split=42)\n",
      "Test score R^2: 0.5157035955123616\n",
      "Train score R^2: 0.5157035955123616\n",
      "Mean Squared Error: 98957046276.9575\n",
      "Parameter set: DecisionTreeRegressor(max_depth=20, min_samples_leaf=60)\n",
      "Test score R^2: 0.6121922981892298\n",
      "Train score R^2: 0.6121922981892298\n",
      "Mean Squared Error: 47672.51062678733\n",
      "Parameter set: DecisionTreeRegressor(max_depth=20, min_samples_leaf=60)\n",
      "Test score R^2: 0.14250945833885176\n",
      "Train score R^2: 0.14250945833885176\n",
      "Mean Squared Error: 9.624984060885597\n",
      "Parameter set: DecisionTreeRegressor(max_depth=20, min_samples_leaf=60)\n",
      "Test score R^2: 0.4325056218164366\n",
      "Train score R^2: 0.4325056218164366\n",
      "Mean Squared Error: 3448.3217119745445\n",
      "Parameter set: DecisionTreeRegressor(max_depth=20, min_samples_leaf=60)\n",
      "Test score R^2: 0.4859759704370552\n",
      "Train score R^2: 0.4859759704370552\n",
      "Mean Squared Error: 105031338679.34148\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.6000000000000001, max_depth=7,\n",
      "                      min_samples_leaf=53, min_samples_split=53)\n",
      "Test score R^2: 0.6441798202604005\n",
      "Train score R^2: 0.6441798202604005\n",
      "Mean Squared Error: 43740.34146474588\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.6000000000000001, max_depth=7,\n",
      "                      min_samples_leaf=53, min_samples_split=53)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.6000000000000001, max_depth=7,\n",
      "                      min_samples_leaf=53, min_samples_split=53)\n",
      "Test score R^2: 0.43684482413295955\n",
      "Train score R^2: 0.43684482413295955\n",
      "Mean Squared Error: 3421.9549916404862\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.6000000000000001, max_depth=7,\n",
      "                      min_samples_leaf=53, min_samples_split=53)\n",
      "Test score R^2: 0.4931640505110051\n",
      "Train score R^2: 0.4931640505110051\n",
      "Mean Squared Error: 103562586968.75864\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=28,\n",
      "                      min_samples_leaf=44, min_samples_split=40)\n",
      "Test score R^2: 0.674980824248782\n",
      "Train score R^2: 0.674980824248782\n",
      "Mean Squared Error: 39954.028859050595\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=28,\n",
      "                      min_samples_leaf=44, min_samples_split=40)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=28,\n",
      "                      min_samples_leaf=44, min_samples_split=40)\n",
      "Test score R^2: 0.47574569176031156\n",
      "Train score R^2: 0.47574569176031156\n",
      "Mean Squared Error: 3185.5778368862666\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=28,\n",
      "                      min_samples_leaf=44, min_samples_split=40)\n",
      "Test score R^2: 0.5253118659699338\n",
      "Train score R^2: 0.5253118659699338\n",
      "Mean Squared Error: 96993773257.58125\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=9, min_samples_leaf=14,\n",
      "                      min_samples_split=38)\n",
      "Test score R^2: 0.8846323876925913\n",
      "Train score R^2: 0.8846323876925913\n",
      "Mean Squared Error: 14181.935268515284\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=9, min_samples_leaf=14,\n",
      "                      min_samples_split=38)\n",
      "Test score R^2: 0.1806842825046534\n",
      "Train score R^2: 0.1806842825046534\n",
      "Mean Squared Error: 9.1964871197868\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=9, min_samples_leaf=14,\n",
      "                      min_samples_split=38)\n",
      "Test score R^2: 0.5777395744607203\n",
      "Train score R^2: 0.5777395744607203\n",
      "Mean Squared Error: 2565.8224107089172\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=9, min_samples_leaf=14,\n",
      "                      min_samples_split=38)\n",
      "Test score R^2: 0.7163141628252372\n",
      "Train score R^2: 0.7163141628252372\n",
      "Mean Squared Error: 57965973435.46246\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=10, min_samples_leaf=28,\n",
      "                      min_samples_split=14)\n",
      "Test score R^2: 0.7875993542032738\n",
      "Train score R^2: 0.7875993542032738\n",
      "Mean Squared Error: 26110.033391811598\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=10, min_samples_leaf=28,\n",
      "                      min_samples_split=14)\n",
      "Test score R^2: 0.20919115906260877\n",
      "Train score R^2: 0.20919115906260877\n",
      "Mean Squared Error: 8.87650897522975\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=10, min_samples_leaf=28,\n",
      "                      min_samples_split=14)\n",
      "Test score R^2: 0.48665447596044953\n",
      "Train score R^2: 0.48665447596044953\n",
      "Mean Squared Error: 3119.2917222484707\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.1, max_depth=10, min_samples_leaf=28,\n",
      "                      min_samples_split=14)\n",
      "Test score R^2: 0.5455241022379151\n",
      "Train score R^2: 0.5455241022379151\n",
      "Mean Squared Error: 92863775220.84695\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=5, min_samples_leaf=24,\n",
      "                      min_samples_split=60)\n",
      "Test score R^2: 0.7815269691092457\n",
      "Train score R^2: 0.7815269691092457\n",
      "Mean Squared Error: 26856.500884781224\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=5, min_samples_leaf=24,\n",
      "                      min_samples_split=60)\n",
      "Test score R^2: 0.15528101406816253\n",
      "Train score R^2: 0.15528101406816253\n",
      "Mean Squared Error: 9.48162852008955\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=5, min_samples_leaf=24,\n",
      "                      min_samples_split=60)\n",
      "Test score R^2: 0.5204067989085913\n",
      "Train score R^2: 0.5204067989085913\n",
      "Mean Squared Error: 2914.199174152767\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=5, min_samples_leaf=24,\n",
      "                      min_samples_split=60)\n",
      "Test score R^2: 0.5499475531433262\n",
      "Train score R^2: 0.5499475531433262\n",
      "Mean Squared Error: 91959924537.88823\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.6000000000000001, max_depth=7,\n",
      "                      min_samples_leaf=48, min_samples_split=26)\n",
      "Test score R^2: 0.674980824248782\n",
      "Train score R^2: 0.674980824248782\n",
      "Mean Squared Error: 39954.028859050595\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.6000000000000001, max_depth=7,\n",
      "                      min_samples_leaf=48, min_samples_split=26)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.6000000000000001, max_depth=7,\n",
      "                      min_samples_leaf=48, min_samples_split=26)\n",
      "Test score R^2: 0.45216237122574277\n",
      "Train score R^2: 0.45216237122574277\n",
      "Mean Squared Error: 3328.8794789221\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.6000000000000001, max_depth=7,\n",
      "                      min_samples_leaf=48, min_samples_split=26)\n",
      "Test score R^2: 0.5157035955123616\n",
      "Train score R^2: 0.5157035955123616\n",
      "Mean Squared Error: 98957046276.9575\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=6, min_samples_leaf=51,\n",
      "                      min_samples_split=58)\n",
      "Test score R^2: 0.6520724875020846\n",
      "Train score R^2: 0.6520724875020846\n",
      "Mean Squared Error: 42770.10992680578\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=6, min_samples_leaf=51,\n",
      "                      min_samples_split=58)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=6, min_samples_leaf=51,\n",
      "                      min_samples_split=58)\n",
      "Test score R^2: 0.43684482413295955\n",
      "Train score R^2: 0.43684482413295955\n",
      "Mean Squared Error: 3421.9549916404862\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=6, min_samples_leaf=51,\n",
      "                      min_samples_split=58)\n",
      "Test score R^2: 0.5157035955123616\n",
      "Train score R^2: 0.5157035955123616\n",
      "Mean Squared Error: 98957046276.9575\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.9, max_depth=26, min_samples_leaf=24,\n",
      "                      min_samples_split=46)\n",
      "Test score R^2: 0.789919150538415\n",
      "Train score R^2: 0.789919150538415\n",
      "Mean Squared Error: 25824.864956727335\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.9, max_depth=26, min_samples_leaf=24,\n",
      "                      min_samples_split=46)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.9, max_depth=26, min_samples_leaf=24,\n",
      "                      min_samples_split=46)\n",
      "Test score R^2: 0.529328831416378\n",
      "Train score R^2: 0.529328831416378\n",
      "Mean Squared Error: 2859.9853535506672\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.9, max_depth=26, min_samples_leaf=24,\n",
      "                      min_samples_split=46)\n",
      "Test score R^2: 0.6163961796920479\n",
      "Train score R^2: 0.6163961796920479\n",
      "Mean Squared Error: 78382372130.95114\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=25,\n",
      "                      min_samples_leaf=21, min_samples_split=24)\n",
      "Test score R^2: 0.789919150538415\n",
      "Train score R^2: 0.789919150538415\n",
      "Mean Squared Error: 25824.864956727335\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=25,\n",
      "                      min_samples_leaf=21, min_samples_split=24)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=25,\n",
      "                      min_samples_leaf=21, min_samples_split=24)\n",
      "Test score R^2: 0.551063863701347\n",
      "Train score R^2: 0.551063863701347\n",
      "Mean Squared Error: 2727.914646562125\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=25,\n",
      "                      min_samples_leaf=21, min_samples_split=24)\n",
      "Test score R^2: 0.6351879826910638\n",
      "Train score R^2: 0.6351879826910638\n",
      "Mean Squared Error: 74542613458.84529\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.9, max_depth=2, min_samples_leaf=3,\n",
      "                      min_samples_split=51)\n",
      "Test score R^2: 0.7815269691092457\n",
      "Train score R^2: 0.7815269691092457\n",
      "Mean Squared Error: 26856.500884781224\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.9, max_depth=2, min_samples_leaf=3,\n",
      "                      min_samples_split=51)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.9, max_depth=2, min_samples_leaf=3,\n",
      "                      min_samples_split=51)\n",
      "Test score R^2: 0.44726705293355085\n",
      "Train score R^2: 0.44726705293355085\n",
      "Mean Squared Error: 3358.6253812657023\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.9, max_depth=2, min_samples_leaf=3,\n",
      "                      min_samples_split=51)\n",
      "Test score R^2: 0.6986552647294888\n",
      "Train score R^2: 0.6986552647294888\n",
      "Mean Squared Error: 61574243866.27392\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=25, min_samples_leaf=44,\n",
      "                      min_samples_split=39)\n",
      "Test score R^2: 0.674980824248782\n",
      "Train score R^2: 0.674980824248782\n",
      "Mean Squared Error: 39954.028859050595\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=25, min_samples_leaf=44,\n",
      "                      min_samples_split=39)\n",
      "Test score R^2: 0.16490931458869063\n",
      "Train score R^2: 0.16490931458869063\n",
      "Mean Squared Error: 9.373554746046546\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=25, min_samples_leaf=44,\n",
      "                      min_samples_split=39)\n",
      "Test score R^2: 0.47574569176031156\n",
      "Train score R^2: 0.47574569176031156\n",
      "Mean Squared Error: 3185.5778368862666\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=25, min_samples_leaf=44,\n",
      "                      min_samples_split=39)\n",
      "Test score R^2: 0.5253118659699338\n",
      "Train score R^2: 0.5253118659699338\n",
      "Mean Squared Error: 96993773257.58125\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=7, min_samples_leaf=14,\n",
      "                      min_samples_split=56)\n",
      "Test score R^2: 0.789919150538415\n",
      "Train score R^2: 0.789919150538415\n",
      "Mean Squared Error: 25824.864956727335\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=7, min_samples_leaf=14,\n",
      "                      min_samples_split=56)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=7, min_samples_leaf=14,\n",
      "                      min_samples_split=56)\n",
      "Test score R^2: 0.5346068116967622\n",
      "Train score R^2: 0.5346068116967622\n",
      "Mean Squared Error: 2827.9142446623696\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=7, min_samples_leaf=14,\n",
      "                      min_samples_split=56)\n",
      "Test score R^2: 0.5628868854192738\n",
      "Train score R^2: 0.5628868854192738\n",
      "Mean Squared Error: 89316010416.3731\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=23, min_samples_leaf=27,\n",
      "                      min_samples_split=44)\n",
      "Test score R^2: 0.789919150538415\n",
      "Train score R^2: 0.789919150538415\n",
      "Mean Squared Error: 25824.864956727335\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=23, min_samples_leaf=27,\n",
      "                      min_samples_split=44)\n",
      "Test score R^2: 0.15528101406816253\n",
      "Train score R^2: 0.15528101406816253\n",
      "Mean Squared Error: 9.48162852008955\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=23, min_samples_leaf=27,\n",
      "                      min_samples_split=44)\n",
      "Test score R^2: 0.5213709259235062\n",
      "Train score R^2: 0.5213709259235062\n",
      "Mean Squared Error: 2908.3407546750736\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=23, min_samples_leaf=27,\n",
      "                      min_samples_split=44)\n",
      "Test score R^2: 0.5504928637189375\n",
      "Train score R^2: 0.5504928637189375\n",
      "Mean Squared Error: 91848500370.03145\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=27, min_samples_leaf=16,\n",
      "                      min_samples_split=8)\n",
      "Test score R^2: 0.8916720808460965\n",
      "Train score R^2: 0.8916720808460965\n",
      "Mean Squared Error: 13316.55831725104\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=27, min_samples_leaf=16,\n",
      "                      min_samples_split=8)\n",
      "Test score R^2: 0.2186186394556533\n",
      "Train score R^2: 0.2186186394556533\n",
      "Mean Squared Error: 8.770689325788974\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=27, min_samples_leaf=16,\n",
      "                      min_samples_split=8)\n",
      "Test score R^2: 0.5876505521979519\n",
      "Train score R^2: 0.5876505521979519\n",
      "Mean Squared Error: 2505.5993652796683\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=27, min_samples_leaf=16,\n",
      "                      min_samples_split=8)\n",
      "Test score R^2: 0.6674688175956249\n",
      "Train score R^2: 0.6674688175956249\n",
      "Mean Squared Error: 67946619675.06114\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=20, min_samples_leaf=38,\n",
      "                      min_samples_split=19)\n",
      "Test score R^2: 0.7751794365385887\n",
      "Train score R^2: 0.7751794365385887\n",
      "Mean Squared Error: 27636.79176739031\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=20, min_samples_leaf=38,\n",
      "                      min_samples_split=19)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=20, min_samples_leaf=38,\n",
      "                      min_samples_split=19)\n",
      "Test score R^2: 0.4794698155499745\n",
      "Train score R^2: 0.4794698155499745\n",
      "Mean Squared Error: 3162.94857849065\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=20, min_samples_leaf=38,\n",
      "                      min_samples_split=19)\n",
      "Test score R^2: 0.5296159165459413\n",
      "Train score R^2: 0.5296159165459413\n",
      "Mean Squared Error: 96114319831.78322\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=6, min_samples_leaf=30,\n",
      "                      min_samples_split=40)\n",
      "Test score R^2: 0.7815269691092457\n",
      "Train score R^2: 0.7815269691092457\n",
      "Mean Squared Error: 26856.500884781224\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=6, min_samples_leaf=30,\n",
      "                      min_samples_split=40)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=6, min_samples_leaf=30,\n",
      "                      min_samples_split=40)\n",
      "Test score R^2: 0.48146213781166225\n",
      "Train score R^2: 0.48146213781166225\n",
      "Mean Squared Error: 3150.8424354585054\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.5, max_depth=6, min_samples_leaf=30,\n",
      "                      min_samples_split=40)\n",
      "Test score R^2: 0.5362524536474875\n",
      "Train score R^2: 0.5362524536474875\n",
      "Mean Squared Error: 94758265764.49924\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.8, max_depth=14, min_samples_leaf=51,\n",
      "                      min_samples_split=49)\n",
      "Test score R^2: 0.6520724875020846\n",
      "Train score R^2: 0.6520724875020846\n",
      "Mean Squared Error: 42770.10992680578\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.8, max_depth=14, min_samples_leaf=51,\n",
      "                      min_samples_split=49)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.8, max_depth=14, min_samples_leaf=51,\n",
      "                      min_samples_split=49)\n",
      "Test score R^2: 0.43684482413295955\n",
      "Train score R^2: 0.43684482413295955\n",
      "Mean Squared Error: 3421.9549916404862\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.8, max_depth=14, min_samples_leaf=51,\n",
      "                      min_samples_split=49)\n",
      "Test score R^2: 0.5157035955123616\n",
      "Train score R^2: 0.5157035955123616\n",
      "Mean Squared Error: 98957046276.9575\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=27,\n",
      "                      min_samples_leaf=4, min_samples_split=38)\n",
      "Test score R^2: 0.896720378950429\n",
      "Train score R^2: 0.896720378950429\n",
      "Mean Squared Error: 12695.980015421923\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=27,\n",
      "                      min_samples_leaf=4, min_samples_split=38)\n",
      "Test score R^2: 0.1806842825046534\n",
      "Train score R^2: 0.1806842825046534\n",
      "Mean Squared Error: 9.1964871197868\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=27,\n",
      "                      min_samples_leaf=4, min_samples_split=38)\n",
      "Test score R^2: 0.6140481047915556\n",
      "Train score R^2: 0.6140481047915556\n",
      "Mean Squared Error: 2345.197329152238\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=27,\n",
      "                      min_samples_leaf=4, min_samples_split=38)\n",
      "Test score R^2: 0.7746192064422078\n",
      "Train score R^2: 0.7746192064422078\n",
      "Mean Squared Error: 46052412141.34417\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=5,\n",
      "                      min_samples_leaf=42, min_samples_split=28)\n",
      "Test score R^2: 0.7390630088879218\n",
      "Train score R^2: 0.7390630088879218\n",
      "Mean Squared Error: 32076.51994436742\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=5,\n",
      "                      min_samples_leaf=42, min_samples_split=28)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=5,\n",
      "                      min_samples_leaf=42, min_samples_split=28)\n",
      "Test score R^2: 0.476473514519019\n",
      "Train score R^2: 0.476473514519019\n",
      "Mean Squared Error: 3181.155296121452\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=5,\n",
      "                      min_samples_leaf=42, min_samples_split=28)\n",
      "Test score R^2: 0.5275820132686264\n",
      "Train score R^2: 0.5275820132686264\n",
      "Mean Squared Error: 96529910488.39572\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=10, min_samples_leaf=49,\n",
      "                      min_samples_split=56)\n",
      "Test score R^2: 0.674980824248782\n",
      "Train score R^2: 0.674980824248782\n",
      "Mean Squared Error: 39954.028859050595\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=10, min_samples_leaf=49,\n",
      "                      min_samples_split=56)\n",
      "Test score R^2: 0.11406948450062537\n",
      "Train score R^2: 0.11406948450062537\n",
      "Mean Squared Error: 9.944211249508166\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=10, min_samples_leaf=49,\n",
      "                      min_samples_split=56)\n",
      "Test score R^2: 0.45216237122574277\n",
      "Train score R^2: 0.45216237122574277\n",
      "Mean Squared Error: 3328.8794789221\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.4, max_depth=10, min_samples_leaf=49,\n",
      "                      min_samples_split=56)\n",
      "Test score R^2: 0.5157035955123616\n",
      "Train score R^2: 0.5157035955123616\n",
      "Mean Squared Error: 98957046276.9575\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=22, min_samples_leaf=3,\n",
      "                      min_samples_split=58)\n",
      "Test score R^2: 0.7815269691092457\n",
      "Train score R^2: 0.7815269691092457\n",
      "Mean Squared Error: 26856.500884781224\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=22, min_samples_leaf=3,\n",
      "                      min_samples_split=58)\n",
      "Test score R^2: 0.19718855402571\n",
      "Train score R^2: 0.19718855402571\n",
      "Mean Squared Error: 9.011233355915582\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=22, min_samples_leaf=3,\n",
      "                      min_samples_split=58)\n",
      "Test score R^2: 0.5543096160237135\n",
      "Train score R^2: 0.5543096160237135\n",
      "Mean Squared Error: 2708.1921635998574\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=0.2, max_depth=22, min_samples_leaf=3,\n",
      "                      min_samples_split=58)\n",
      "Test score R^2: 0.5595820029015193\n",
      "Train score R^2: 0.5595820029015193\n",
      "Mean Squared Error: 89991302260.828\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=2, min_samples_leaf=15,\n",
      "                      min_samples_split=52)\n",
      "Test score R^2: 0.7815269691092457\n",
      "Train score R^2: 0.7815269691092457\n",
      "Mean Squared Error: 26856.500884781224\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=2, min_samples_leaf=15,\n",
      "                      min_samples_split=52)\n",
      "Test score R^2: 0.11734665711716263\n",
      "Train score R^2: 0.11734665711716263\n",
      "Mean Squared Error: 9.907426314087378\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=2, min_samples_leaf=15,\n",
      "                      min_samples_split=52)\n",
      "Test score R^2: 0.44726705293355085\n",
      "Train score R^2: 0.44726705293355085\n",
      "Mean Squared Error: 3358.6253812657023\n",
      "Parameter set: DecisionTreeRegressor(ccp_alpha=1.0, max_depth=2, min_samples_leaf=15,\n",
      "                      min_samples_split=52)\n",
      "Test score R^2: 0.519148873576033\n",
      "Train score R^2: 0.519148873576033\n",
      "Mean Squared Error: 98253067189.71977\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Configuration: {'model__ccp_alpha': 0.4, 'model__max_depth': 11, 'model__min_samples_split': 8, 'model__min_samples_leaf': 7}\n",
      "Best Test Score: 0.6866351370414695\n"
     ]
    }
   ],
   "source": [
    "test_scores = (\n",
    "    []\n",
    ")  # list of test scores calculated across datasets, for each configuration\n",
    "config_ids = []\n",
    "best_config = None\n",
    "best_test_score = float(\"-inf\")\n",
    "\n",
    "for i, config in enumerate(configuration_grid_decision_tree):\n",
    "    results = evaluate_pipeline_on_datasets(\n",
    "        get_decision_tree_pipeline(), config, train_datasets\n",
    "    )\n",
    "\n",
    "    aggregated_test_score = np.mean([result[0] for result in results])\n",
    "    test_scores.append(aggregated_test_score)\n",
    "    config_ids.append(i)\n",
    "\n",
    "    if aggregated_test_score > best_test_score:\n",
    "        best_test_score = aggregated_test_score\n",
    "        best_config = config\n",
    "\n",
    "plt.boxplot(test_scores)\n",
    "plt.xlabel(\"Configuration ID\")\n",
    "plt.ylabel(\"Test Score\")\n",
    "plt.title(\"Test Scores for Decision Tree\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Best Configuration:\", best_config)\n",
    "print(\"Best Test Score:\", best_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bayes_config_candidates_decision_tree():\n",
    "    return [\n",
    "        [\n",
    "            (\n",
    "                {\n",
    "                    \"model__ccp_alpha\": Real(0.11, 1.21, prior=\"log-uniform\"),\n",
    "                    \"model__max_depth\": Integer(1, 31, prior=\"log-uniform\"),\n",
    "                    \"model__min_samples_split\": Integer(2, 61, prior=\"log-uniform\"),\n",
    "                    \"model__min_samples_leaf\": Integer(2, 61, prior=\"log-uniform\"),\n",
    "                },\n",
    "                30,\n",
    "            )\n",
    "        ],\n",
    "        # [\n",
    "        #     (\n",
    "        #         {\n",
    "        #             \"model__ccp_alpha\": Real(0.11, 1.21, prior=\"log-uniform\"),\n",
    "        #             \"model__max_depth\": Integer(1, 31, prior=\"log-uniform\"),\n",
    "        #             \"model__min_samples_split\": Integer(2, 61, prior=\"log-uniform\"),\n",
    "        #             \"model__min_samples_leaf\": Integer(2, 61, prior=\"log-uniform\"),\n",
    "        #         },\n",
    "        #         20,\n",
    "        #     )\n",
    "        # ],\n",
    "        # [\n",
    "        #     (\n",
    "        #         {\n",
    "        #             \"model__ccp_alpha\": Real(0.11, 1.21, prior=\"log-uniform\"),\n",
    "        #             \"model__max_depth\": Integer(1, 31, prior=\"log-uniform\"),\n",
    "        #             \"model__min_samples_split\": Integer(2, 61, prior=\"log-uniform\"),\n",
    "        #             \"model__min_samples_leaf\": Integer(2, 61, prior=\"log-uniform\"),\n",
    "        #         },\n",
    "        #         30,\n",
    "        #     )\n",
    "        # ],\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Score = 0.8762183931068073\n",
      "Iteration 2: Score = 0.7765091670213871\n",
      "Iteration 3: Score = 0.8890974461606083\n",
      "Iteration 4: Score = 0.8908639821293663\n",
      "Iteration 5: Score = 0.8774095909186859\n",
      "Iteration 6: Score = 0.9318420801380716\n",
      "Iteration 7: Score = 0.6938644238320535\n",
      "Iteration 8: Score = 0.7805398305254894\n",
      "Iteration 9: Score = 0.8335879055710477\n",
      "Iteration 10: Score = 0.6397575960991398\n",
      "Iteration 11: Score = 0.9270504708377976\n",
      "Iteration 12: Score = 0.9432371465404303\n",
      "Iteration 13: Score = 0.6938644238320535\n",
      "Iteration 14: Score = 0.7819467475731763\n",
      "Iteration 15: Score = 0.9322066848009376\n",
      "Iteration 16: Score = 0.9304936672860169\n",
      "Iteration 17: Score = 0.9421203034989487\n",
      "Iteration 18: Score = 0.9306288469089408\n",
      "Iteration 19: Score = 0.9287584839253265\n",
      "Iteration 20: Score = -0.05320919309927987\n",
      "Iteration 21: Score = 0.9503507418711207\n",
      "Iteration 22: Score = 0.7819467475731763\n",
      "Iteration 23: Score = 0.9315701662081306\n",
      "Iteration 24: Score = 0.8760732954204167\n",
      "Iteration 25: Score = 0.9304419123149306\n",
      "Iteration 26: Score = 0.6938644238320535\n",
      "Iteration 27: Score = 0.951146837527064\n",
      "Iteration 28: Score = 0.9518292024610335\n",
      "Iteration 29: Score = 0.9097933309590814\n",
      "Iteration 30: Score = 0.948985029580462\n",
      "30\n",
      "Iteration 1: Score = -0.06618585727877435\n",
      "Iteration 2: Score = -0.0045824033410301725\n",
      "Iteration 3: Score = -0.06999738162620946\n",
      "Iteration 4: Score = -0.043650291762457515\n",
      "Iteration 5: Score = -0.1164205777669128\n",
      "Iteration 6: Score = -0.04533353855900311\n",
      "Iteration 7: Score = -0.06270537586976677\n",
      "Iteration 8: Score = -0.06366254264668354\n",
      "Iteration 9: Score = -0.10927661751029953\n",
      "Iteration 10: Score = -0.0379659232997178\n",
      "Iteration 11: Score = -0.014478364321510905\n",
      "Iteration 12: Score = -0.014478364321510905\n",
      "Iteration 13: Score = -0.055590382102869776\n",
      "Iteration 14: Score = -0.014478364321510905\n",
      "Iteration 15: Score = -0.014478364321510905\n",
      "Iteration 16: Score = -0.03135781838048128\n",
      "Iteration 17: Score = -0.014478364321510905\n",
      "Iteration 18: Score = -0.5428452015101486\n",
      "Iteration 19: Score = -0.014478364321510905\n",
      "Iteration 20: Score = -0.0312798465967832\n",
      "Iteration 21: Score = -0.014478364321510905\n",
      "Iteration 22: Score = 0.003896919976647828\n",
      "Iteration 23: Score = -0.06270537586976677\n",
      "Iteration 24: Score = -0.126856767562657\n",
      "Iteration 25: Score = -0.014478364321510905\n",
      "Iteration 26: Score = -0.06270537586976677\n",
      "Iteration 27: Score = 0.014314094694312062\n",
      "Iteration 28: Score = 0.003896919976647828\n",
      "Iteration 29: Score = -0.10927661751029953\n",
      "Iteration 30: Score = 0.014314094694312062\n",
      "30\n",
      "Iteration 1: Score = 0.2119479930883988\n",
      "Iteration 2: Score = 0.23219900167516264\n",
      "Iteration 3: Score = 0.23709514396727654\n",
      "Iteration 4: Score = 0.31258055282398645\n",
      "Iteration 5: Score = 0.33028591575621064\n",
      "Iteration 6: Score = 0.3253370204695152\n",
      "Iteration 7: Score = 0.20738262145941375\n",
      "Iteration 8: Score = 0.2587183392255283\n",
      "Iteration 9: Score = 0.11860658519080466\n",
      "Iteration 10: Score = 0.027718389739687564\n",
      "Iteration 11: Score = 0.33364484126355987\n",
      "Iteration 12: Score = 0.319287802067998\n",
      "Iteration 13: Score = 0.23219900167516264\n",
      "Iteration 14: Score = 0.3314982517854963\n",
      "Iteration 15: Score = 0.3059204578389973\n",
      "Iteration 16: Score = 0.319287802067998\n",
      "Iteration 17: Score = 0.3169069034207741\n",
      "Iteration 18: Score = 0.3345514659513295\n",
      "Iteration 19: Score = 0.319287802067998\n",
      "Iteration 20: Score = 0.32093422638984065\n",
      "Iteration 21: Score = 0.23219900167516264\n",
      "Iteration 22: Score = 0.23219900167516264\n",
      "Iteration 23: Score = 0.28917376817331497\n",
      "Iteration 24: Score = 0.35090510941645536\n",
      "Iteration 25: Score = 0.23219900167516264\n",
      "Iteration 26: Score = 0.20128288695483923\n",
      "Iteration 27: Score = 0.33364484126355987\n",
      "Iteration 28: Score = 0.3492684861332664\n",
      "Iteration 29: Score = 0.35090510941645536\n",
      "Iteration 30: Score = 0.23219900167516264\n",
      "30\n",
      "Iteration 1: Score = 0.6311598344597448\n",
      "Iteration 2: Score = 0.6400434978274822\n",
      "Iteration 3: Score = 0.41394011945668574\n",
      "Iteration 4: Score = 0.5128097193980137\n",
      "Iteration 5: Score = 0.6724493039998096\n",
      "Iteration 6: Score = 0.5675037841259892\n",
      "Iteration 7: Score = 0.645254051525578\n",
      "Iteration 8: Score = 0.5229584702354715\n",
      "Iteration 9: Score = 0.5229584702354715\n",
      "Iteration 10: Score = 0.6119483279315314\n",
      "Iteration 11: Score = 0.6148368221690095\n",
      "Iteration 12: Score = 0.6785380077586121\n",
      "Iteration 13: Score = 0.645254051525578\n",
      "Iteration 14: Score = 0.7034512887631961\n",
      "Iteration 15: Score = 0.5351226394991274\n",
      "Iteration 16: Score = 0.3591708745433257\n",
      "Iteration 17: Score = 0.6111860047181427\n",
      "Iteration 18: Score = 0.45246742696842296\n",
      "Iteration 19: Score = 0.7193877351268998\n",
      "Iteration 20: Score = 0.5075652640514073\n",
      "Iteration 21: Score = 0.7047204266310645\n",
      "Iteration 22: Score = 0.5588752367297154\n",
      "Iteration 23: Score = 0.7159106077281389\n",
      "Iteration 24: Score = 0.7153625235861887\n",
      "Iteration 25: Score = 0.7086873638943771\n",
      "Iteration 26: Score = 0.6390037710897385\n",
      "Iteration 27: Score = 0.7152157799188695\n",
      "Iteration 28: Score = 0.7070104537332913\n",
      "Iteration 29: Score = 0.7005545582265402\n",
      "Iteration 30: Score = 0.7221472937329689\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "candidates = get_bayes_config_candidates_decision_tree()\n",
    "\n",
    "# calculate all configs\n",
    "configs = configs_from_candidates(\n",
    "    candidates=candidates,\n",
    "    pipeline=get_decision_tree_pipeline(),\n",
    "    train_datasets=get_train_datasets(),\n",
    "    retries=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find optimal theta\n",
    "\n",
    "(\n",
    "    optimal_config,\n",
    "    last_idx_of_config_with_significant_improvement,\n",
    ") = find_optimal_configuration_for_all_datasets(\n",
    "    config_space=configs,\n",
    "    train_datasets=train_datasets,\n",
    "    test_datasets=test_datasets,\n",
    "    model=get_decision_tree_pipeline(),\n",
    "    summary_func=np.mean,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__ccp_alpha': 0.23296518681616513, 'model__max_depth': 4, 'model__min_samples_leaf': 12, 'model__min_samples_split': 32}\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;column_transformer&#x27;,\n",
       "                 ColumnTransformer(n_jobs=-1,\n",
       "                                   transformers=[(&#x27;num_pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;scale&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000189AFA6CF70&gt;),\n",
       "                                                 (&#x27;cat_pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;one-hot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000189AD1CDCD0&gt;)])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 DecisionTreeRegressor(ccp_alpha=0.7000000000000001,\n",
       "                                       max_depth=5, min_samples_leaf=4,\n",
       "                                       min_samples_split=16))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;column_transformer&#x27;,\n",
       "                 ColumnTransformer(n_jobs=-1,\n",
       "                                   transformers=[(&#x27;num_pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;scale&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000189AFA6CF70&gt;),\n",
       "                                                 (&#x27;cat_pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;one-hot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000189AD1CDCD0&gt;)])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 DecisionTreeRegressor(ccp_alpha=0.7000000000000001,\n",
       "                                       max_depth=5, min_samples_leaf=4,\n",
       "                                       min_samples_split=16))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">column_transformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(n_jobs=-1,\n",
       "                  transformers=[(&#x27;num_pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;impute&#x27;, SimpleImputer()),\n",
       "                                                 (&#x27;scale&#x27;, MinMaxScaler())]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000189AFA6CF70&gt;),\n",
       "                                (&#x27;cat_pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;one-hot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=False))]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000189AD1CDCD0&gt;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num_pipeline</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000189AFA6CF70&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat_pipeline</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000189AD1CDCD0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse=False)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(ccp_alpha=0.7000000000000001, max_depth=5,\n",
       "                      min_samples_leaf=4, min_samples_split=16)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('column_transformer',\n",
       "                 ColumnTransformer(n_jobs=-1,\n",
       "                                   transformers=[('num_pipeline',\n",
       "                                                  Pipeline(steps=[('impute',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('scale',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x00000189AFA6CF70>),\n",
       "                                                 ('cat_pipeline',\n",
       "                                                  Pipeline(steps=[('impute',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('one-hot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x00000189AD1CDCD0>)])),\n",
       "                ('model',\n",
       "                 DecisionTreeRegressor(ccp_alpha=0.7000000000000001,\n",
       "                                       max_depth=5, min_samples_leaf=4,\n",
       "                                       min_samples_split=16))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(optimal_config)\n",
    "print(last_idx_of_config_with_significant_improvement)\n",
    "optimal_decision_tree = get_decision_tree_pipeline()\n",
    "optimal_decision_tree.set_params(**optimal_config_decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9630306807645214\n",
      "best config: {'model__ccp_alpha': 0.8047339903497972, 'model__max_depth': 10, 'model__min_samples_leaf': 5, 'model__min_samples_split': 3}\n",
      "score: 0.16160537465256997\n",
      "best config: {'model__ccp_alpha': 0.13363717240429412, 'model__max_depth': 19, 'model__min_samples_leaf': 54, 'model__min_samples_split': 54}\n",
      "score: 0.43484489814756955\n",
      "best config: {'model__ccp_alpha': 0.6452511101720104, 'model__max_depth': 21, 'model__min_samples_leaf': 5, 'model__min_samples_split': 48}\n",
      "score: 0.6848200051719223\n",
      "best config: {'model__ccp_alpha': 1.21, 'model__max_depth': 16, 'model__min_samples_leaf': 2, 'model__min_samples_split': 3}\n"
     ]
    }
   ],
   "source": [
    "# find theta^(j)\n",
    "best_configs_for_each_dataset = get_best_configs_for_each_set(\n",
    "    pipeline=get_decision_tree_pipeline(),\n",
    "    config_space=configs,\n",
    "    train_datasets=get_train_datasets(),\n",
    "    test_datasets=get_test_datasets(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d^j: -0.0013241405976243126\n",
      "d^j: 0.09392931267054028\n",
      "d^j: 0.06758087241703248\n",
      "d^j: -0.014847438829052262\n"
     ]
    }
   ],
   "source": [
    "# find d^j\n",
    "tunability_on_datasets = calculate_tunability_on_each_set(\n",
    "    get_train_datasets(), get_test_datasets(), best_configs_for_each_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tunability data\n",
    "tunability_data = [tunability_on_datasets]\n",
    "\n",
    "# create box plot\n",
    "sns.boxplot(data=tunability_data)\n",
    "\n",
    "# add strip plot\n",
    "sns.stripplot(data=tunability_data, color=\"black\", size=4)\n",
    "\n",
    "# add labels and title\n",
    "plt.xlabel(\"Dataset\")\n",
    "plt.ylabel(\"Tunability\")\n",
    "plt.title(\"Tunability per Dataset\")\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elasticnet_pipeline() -> Pipeline:\n",
    "    elastic_net = ElasticNet(max_iter=10000)\n",
    "    col_trans: ColumnTransformer = get_column_transformer()\n",
    "    decision_tree_pipeline = Pipeline(\n",
    "        steps=[(\"column_transformer\", col_trans), (\"model\", elastic_net)]\n",
    "    )\n",
    "    return decision_tree_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameter_grid_for_elasticnet():\n",
    "    # parameters space\n",
    "    random.seed(42)\n",
    "    alpha = [i * 0.05 for i in range(21)]\n",
    "    l1_ratio = [i * 0.05 for i in range(21)]\n",
    "    all_combinations = list(\n",
    "        itertools.product(\n",
    "            alpha,\n",
    "            l1_ratio,\n",
    "        )\n",
    "    )\n",
    "    selected_combinations: List[Tuple[float, int, int, int]] = random.sample(\n",
    "        all_combinations, 100\n",
    "    )\n",
    "    parameter_names = [\n",
    "        \"model__alpha\",\n",
    "        \"model__l1_ratio\",\n",
    "    ]\n",
    "\n",
    "    parameters_grid_elasticnet = [\n",
    "        dict(zip(parameter_names, combination)) for combination in selected_combinations\n",
    "    ]\n",
    "    return parameters_grid_elasticnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.574e+05, tolerance: 1.561e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.203e+03, tolerance: 3.098e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.063e+05, tolerance: 2.145e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.107e+12, tolerance: 4.005e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.863e+11, tolerance: 4.005e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.092e+10, tolerance: 4.005e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.574e+05, tolerance: 1.561e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.203e+03, tolerance: 3.098e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.063e+05, tolerance: 2.145e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.107e+12, tolerance: 4.005e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.574e+05, tolerance: 1.561e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.203e+03, tolerance: 3.098e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.063e+05, tolerance: 2.145e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.107e+12, tolerance: 4.005e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.574e+05, tolerance: 1.561e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.203e+03, tolerance: 3.098e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.063e+05, tolerance: 2.145e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.107e+12, tolerance: 4.005e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.574e+05, tolerance: 1.561e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.203e+03, tolerance: 3.098e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.063e+05, tolerance: 2.145e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.107e+12, tolerance: 4.005e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.332e+06, tolerance: 1.561e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.536e+03, tolerance: 3.098e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e+06, tolerance: 2.145e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.800e+13, tolerance: 4.005e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.760e+06, tolerance: 1.561e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.487e+03, tolerance: 3.098e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.677e+05, tolerance: 2.145e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.336e+13, tolerance: 4.005e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.508e+06, tolerance: 1.561e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.538e+03, tolerance: 3.098e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.025e+06, tolerance: 2.145e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.826e+13, tolerance: 4.005e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.454e+06, tolerance: 1.561e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.537e+03, tolerance: 3.098e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.023e+06, tolerance: 2.145e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.818e+13, tolerance: 4.005e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.862e+11, tolerance: 4.005e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.499e+06, tolerance: 1.561e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.525e+03, tolerance: 3.098e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.782e+05, tolerance: 2.145e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.670e+13, tolerance: 4.005e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.008e+06, tolerance: 1.561e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.532e+03, tolerance: 3.098e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e+06, tolerance: 2.145e+02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\adamd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.751e+13, tolerance: 4.005e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "train_datasets: List[Tuple[DataFrame, Series]] = get_train_datasets()\n",
    "elastic_net_pipeline: Pipeline = get_elasticnet_pipeline()\n",
    "parameters_grid_elasticnet = get_parameter_grid_for_elasticnet()\n",
    "optimal_config_elasticnet = find_optimal_configuration_for_all_datasets(\n",
    "    config_space=parameters_grid_elasticnet,\n",
    "    train_datasets=train_datasets,\n",
    "    test_datasets=test_datasets,\n",
    "    model=elastic_net_pipeline,\n",
    "    summary_func=np.mean,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'model__alpha': 0.05, 'model__l1_ratio': 0.9500000000000001}, 60)\n"
     ]
    }
   ],
   "source": [
    "print(optimal_config_elasticnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sklearn.pipeline.Pipeline.set_params() argument after ** must be a mapping, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\adamd\\_prog\\autoML\\PD\\AutoML_HM1\\solution.ipynb Cell 51\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/adamd/_prog/autoML/PD/AutoML_HM1/solution.ipynb#Y166sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m evaluate_pipeline_on_datasets(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adamd/_prog/autoML/PD/AutoML_HM1/solution.ipynb#Y166sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     get_elasticnet_pipeline(), optimal_config_elasticnet, train_datasets\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/adamd/_prog/autoML/PD/AutoML_HM1/solution.ipynb#Y166sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\adamd\\_prog\\autoML\\PD\\AutoML_HM1\\utills\\pipeline.py:53\u001b[0m, in \u001b[0;36mevaluate_pipeline_on_datasets\u001b[1;34m(pipeline, optimal_config, datasets)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate_pipeline_on_datasets\u001b[39m(\n\u001b[0;32m     51\u001b[0m     pipeline: Pipeline, optimal_config, datasets: List[Tuple[DataFrame, Series]]\n\u001b[0;32m     52\u001b[0m ):\n\u001b[1;32m---> 53\u001b[0m     pipeline\u001b[39m.\u001b[39mset_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptimal_config)\n\u001b[0;32m     54\u001b[0m     results: List[Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]] \u001b[39m=\u001b[39m []\n\u001b[0;32m     55\u001b[0m     \u001b[39mfor\u001b[39;00m X, y \u001b[39min\u001b[39;00m datasets:\n",
      "\u001b[1;31mTypeError\u001b[0m: sklearn.pipeline.Pipeline.set_params() argument after ** must be a mapping, not tuple"
     ]
    }
   ],
   "source": [
    "evaluate_pipeline_on_datasets(\n",
    "    get_elasticnet_pipeline(), optimal_config_elasticnet, train_datasets\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_forest_pipeline():\n",
    "    random_forest = RandomForestRegressor()\n",
    "    col_trans: ColumnTransformer = get_column_transformer()\n",
    "    random_forest_pipeline = Pipeline(\n",
    "        steps=[(\"column_transformer\", col_trans), (\"model\", random_forest)]\n",
    "    )\n",
    "    return random_forest_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameter_grid_for_random_forest():\n",
    "    # parameters space\n",
    "    random.seed(42)\n",
    "    max_depth_values = range(1, 31, 1)\n",
    "    min_samples_split_values = range(2, 61, 1)\n",
    "    min_samples_leaf_values = range(1, 61, 1)\n",
    "    n_estimators_values = range(1, 200, 1)\n",
    "\n",
    "    all_combinations = list(\n",
    "        itertools.product(\n",
    "            max_depth_values,\n",
    "            min_samples_split_values,\n",
    "            min_samples_leaf_values,\n",
    "            n_estimators_values,\n",
    "        )\n",
    "    )\n",
    "    selected_combinations: List[Tuple[float, int, int, int]] = random.sample(\n",
    "        all_combinations, 100\n",
    "    )\n",
    "    parameter_names = [\n",
    "        \"model__max_depth\",\n",
    "        \"model__min_samples_split\",\n",
    "        \"model__min_samples_leaf\",\n",
    "        \"model__n_estimators\",\n",
    "    ]\n",
    "\n",
    "    parameters_grid_random_forest = [\n",
    "        dict(zip(parameter_names, combination)) for combination in selected_combinations\n",
    "    ]\n",
    "    return parameters_grid_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets: List[Tuple[DataFrame, Series]] = get_train_datasets()\n",
    "random_forest_pipeline: Pipeline = get_random_forest_pipeline()\n",
    "parameters_grid_random_forest = get_parameter_grid_for_random_forest()\n",
    "\n",
    "optimal_config_random_forest = find_optimal_configuration_for_all_datasets(\n",
    "    config_space=parameters_grid_random_forest,\n",
    "    train_datasets=train_datasets,\n",
    "    model=random_forest_pipeline,\n",
    "    summary_func=np.mean,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimal_config_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_pipeline_on_datasets(\n",
    "    get_random_forest_pipeline(), optimal_config_random_forest, train_datasets\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO\n",
    "- dla każdej konfiguracje z paratmers_grid trzeba ją porównać do optymalnej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes - decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('model__ccp_alpha', 0.11), ('model__max_depth', 17), ('model__min_samples_leaf', 2), ('model__min_samples_split', 7)])\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "decision_tree_params = {\n",
    "    \"model__ccp_alpha\": Real(0.11, 1.21, prior=\"log-uniform\"),\n",
    "    \"model__max_depth\": Integer(1, 31, prior=\"log-uniform\"),\n",
    "    \"model__min_samples_split\": Integer(2, 61, prior=\"log-uniform\"),\n",
    "    \"model__min_samples_leaf\": Integer(2, 61, prior=\"log-uniform\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9511259336021848\n"
     ]
    }
   ],
   "source": [
    "config = get_bayes_config(\n",
    "    get_decision_tree_pipeline(),\n",
    "    [(decision_tree_params, 40)],\n",
    "    X_train_fish_market,\n",
    "    y_train_fish_market,\n",
    ")\n",
    "model = get_decision_tree_pipeline()\n",
    "model.set_params(**config)\n",
    "model.fit(X_train_fish_market, y_train_fish_market)\n",
    "score = model.score(X_test_fish_market, y_test_fish_market)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
