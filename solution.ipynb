{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import openml\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# from evaluate_pipeline import evaluate_pipeline\n",
    "# from load_dataset import load_dataset_from_id\n",
    "# from perform_optimazaion_of_pipeline_with_random_search import (\n",
    "#     perform_optimazaion_of_pipeline_with_random_search,\n",
    "# )\n",
    "# from split_dataset import split_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utill functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_optimazaion_of_pipeline_with_random_search(\n",
    "    pipeline: Pipeline,\n",
    "    param_grid: Dict[str, Any],\n",
    "    X: DataFrame,\n",
    "    y: DataFrame,\n",
    "    n_iter: int = 100,\n",
    ") -> RandomizedSearchCV:\n",
    "    search: RandomizedSearchCV = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        n_iter=n_iter,\n",
    "        n_jobs=-1,\n",
    "        cv=5,\n",
    "    )\n",
    "    search.fit(X, y)\n",
    "    return search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(\n",
    "    data: pd.DataFrame, class_: str\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    X: pd.DataFrame = data.drop(labels=class_, axis=1)\n",
    "    y: pd.DataFrame = data[class_]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_from_id(id: int) -> DataFrame:\n",
    "    return openml.datasets.get_dataset(dataset_id=id).get_data(\n",
    "        dataset_format=\"dataframe\"\n",
    "    )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mse(model: Pipeline, X_test: pd.DataFrame, y_test: pd.Series):\n",
    "    # Ensure X_test and y_test are the correct types\n",
    "    if not isinstance(X_test, (pd.DataFrame, np.ndarray)):\n",
    "        raise ValueError(\"X_test must be a pandas DataFrame or numpy array\")\n",
    "    if not isinstance(y_test, (pd.Series, np.ndarray)):\n",
    "        raise ValueError(\"y_test must be a pandas Series or numpy array\")\n",
    "\n",
    "    # Generating predictions and calculating MSE\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_random_search_optimizer(\n",
    "    model: RandomizedSearchCV, X_test: pd.DataFrame, y_test: pd.Series\n",
    "):\n",
    "    # Ensure X_test and y_test are the correct types\n",
    "    if not isinstance(X_test, (pd.DataFrame, np.ndarray)):\n",
    "        raise ValueError(\"X_test must be a pandas DataFrame or numpy array\")\n",
    "    if not isinstance(y_test, (pd.Series, np.ndarray)):\n",
    "        raise ValueError(\"y_test must be a pandas Series or numpy array\")\n",
    "\n",
    "    # Evaluating the best model on the test set\n",
    "    test_score = model.score(X_test, y_test)\n",
    "\n",
    "    # Printing information about the best model and its performance\n",
    "    print(\"Test Score of the best model: \" + str(test_score))\n",
    "    print(\"Best Score of train set: \" + str(model.best_score_))\n",
    "    print(\"Best parameter set: \" + str(model.best_params_))\n",
    "\n",
    "    calculate_mse(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AutoML_HM1\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AutoML_HM1\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AutoML_HM1\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n",
      "c:\\JAN_CICHOMSKI\\STUDIA\\STUDIA_SEMESTR_7_2023_ZIMA\\auto_ml\\homeworks\\homework_1\\AutoML_HM1\\.venv\\lib\\site-packages\\openml\\datasets\\functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "fish_market_dataset_id = (\n",
    "    43308  # https://www.openml.org/search?type=data&id=43308&sort=runs&status=active\n",
    ")\n",
    "liver_disorders_dataset_id = (\n",
    "    8  # https://www.openml.org/search?type=data&id=8&sort=runs&status=active\n",
    ")\n",
    "diabetes_dataset_id = (\n",
    "    44223  # https://www.openml.org/search?type=data&id=44223&sort=runs&status=active\n",
    ")\n",
    "\n",
    "lisbona_house_prices_dataset_id = (\n",
    "    43660  # https://www.openml.org/search?type=data&id=43660&sort=runs&status=active\n",
    ")\n",
    "\n",
    "\n",
    "fish_market_dataset: DataFrame = load_dataset_from_id(id=fish_market_dataset_id)\n",
    "fish_market_regression_class = \"Weight\"\n",
    "\n",
    "liver_disorders_dataset: DataFrame = load_dataset_from_id(id=liver_disorders_dataset_id)\n",
    "liver_disorders_regression_class = \"drinks\"\n",
    "diabetes_dataset: DataFrame = load_dataset_from_id(id=diabetes_dataset_id)\n",
    "diabetes_regression_class = \"class\"\n",
    "\n",
    "lisbona_house_prices_dataset: DataFrame = load_dataset_from_id(\n",
    "    id=lisbona_house_prices_dataset_id\n",
    ")\n",
    "lisbona_house_prices_regression_class = \"Price\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_train_fish_market,\n",
    "    X_test_fish_market,\n",
    "    y_train_fish_market,\n",
    "    y_test_fish_market,\n",
    ") = split_dataset(data=fish_market_dataset, class_=fish_market_regression_class)\n",
    "\n",
    "(\n",
    "    X_train_liver_disorders,\n",
    "    X_test_liver_disorders,\n",
    "    y_train_liver_disorders,\n",
    "    y_test_liver_disorders,\n",
    ") = split_dataset(data=liver_disorders_dataset, class_=liver_disorders_regression_class)\n",
    "\n",
    "X_train_diabetes, X_test_diabetes, y_train_diabetes, y_test_diabetes = split_dataset(\n",
    "    diabetes_dataset, diabetes_regression_class\n",
    ")\n",
    "\n",
    "(\n",
    "    X_train_lisbona_house_prices,\n",
    "    X_test_lisbona_house_prices,\n",
    "    y_train_lisbona_house_prices,\n",
    "    y_test_lisbona_house_prices,\n",
    ") = split_dataset(lisbona_house_prices_dataset, lisbona_house_prices_regression_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create generic column transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline(\n",
    "    steps=[(\"impute\", SimpleImputer(strategy=\"mean\")), (\"scale\", MinMaxScaler())]\n",
    ")\n",
    "cat_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"one-hot\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "col_trans = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num_pipeline\", num_pipeline, make_column_selector(dtype_include=np.number)),\n",
    "        (\"cat_pipeline\", cat_pipeline, make_column_selector(dtype_include=object)),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_net = ElasticNet()\n",
    "knn = KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeRegressor()\n",
    "\n",
    "decision_tree_pipeline = Pipeline(\n",
    "    steps=[(\"column_transformer\", col_trans), (\"model\", decision_tree)]\n",
    ")\n",
    "\n",
    "decision_tree_params = {\n",
    "    \"model__ccp_alpha\": [i * 0.1 for i in range(11)],\n",
    "    \"model__max_depth\": range(1, 31, 1),\n",
    "    \"model__min_samples_split\": range(2, 61, 1),\n",
    "    \"model__min_samples_leaf\": range(1, 61, 1),\n",
    "}\n",
    "\n",
    "rs_decision_tree = perform_optimazaion_of_pipeline_with_random_search(\n",
    "    decision_tree_pipeline,\n",
    "    decision_tree_params,\n",
    "    X_train_fish_market,\n",
    "    y_train_fish_market,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score of the best model: 0.9509240510031336\n",
      "Best Score of train set: 0.9338157406641239\n",
      "Best parameter set: {'model__min_samples_split': 5, 'model__min_samples_leaf': 2, 'model__max_depth': 7, 'model__ccp_alpha': 0.1}\n",
      "Mean Squared Error: 6980.527986111111\n"
     ]
    }
   ],
   "source": [
    "evaluate_random_search_optimizer(\n",
    "    rs_decision_tree, X_test_fish_market, y_test_fish_market\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
