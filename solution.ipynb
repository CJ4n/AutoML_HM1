{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from pandas import DataFrame, Series\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real\n",
    "\n",
    "from utills.dataset import load_dataset_from_id, split_dataset\n",
    "from utills.pipeline import evaluate_pipeline_on_datasets, get_column_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utill functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_optimazaion_of_pipeline_with_bayesian_method(\n",
    "    pipeline: Pipeline,\n",
    "    search_space: Dict[str, Any],\n",
    "    X: DataFrame,\n",
    "    y: DataFrame,\n",
    "    n_iter=100,\n",
    ") -> BayesSearchCV:\n",
    "    opt: BayesSearchCV = BayesSearchCV(\n",
    "        pipeline,\n",
    "        # [(space, # of evaluations)]\n",
    "        search_spaces=search_space,\n",
    "        n_iter=n_iter,\n",
    "        n_jobs=-1,\n",
    "        cv=5,\n",
    "    )\n",
    "    opt.fit(X, y)\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bayes_best_configuration(\n",
    "    pipeline: Pipeline,\n",
    "    search,  #: List[(Dict[str, object], int)],\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    X_test,\n",
    "    Y_test,\n",
    "):\n",
    "    max = float(\"-inf\")\n",
    "    best = None\n",
    "    iter = None\n",
    "    for config in search:\n",
    "        model = perform_optimazaion_of_pipeline_with_bayesian_method(\n",
    "            pipeline, [config], X_train, Y_train\n",
    "        )\n",
    "        score = model.score(X_test, Y_test)\n",
    "        if max < score:\n",
    "            best = model.best_params_\n",
    "            iter = config[1]\n",
    "    return (best, iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_pipeline_over_params_combinations(\n",
    "    pipeline: Pipeline,\n",
    "    parameters_grid: List[dict],\n",
    "    X: DataFrame,\n",
    "    y: DataFrame,\n",
    "    X_val: DataFrame,\n",
    "    y_val: DataFrame,\n",
    ") -> Pipeline:\n",
    "    # thats the teta^(j)*\n",
    "    best_score = float(\"-inf\")\n",
    "    best_params = None\n",
    "\n",
    "    for params in parameters_grid:\n",
    "        # Update the pipeline parameters\n",
    "        pipeline_params = {f\"{key}\": value for key, value in params.items()}\n",
    "        pipeline.set_params(**pipeline_params)\n",
    "\n",
    "        pipeline.fit(X, y)\n",
    "        score = pipeline.score(X_val, y_val)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params = pipeline_params\n",
    "\n",
    "    pipeline.set_params(**best_params)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(model: Pipeline, X, y) -> float:\n",
    "    model.fit(X=X, y=y)\n",
    "    return model.score(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(\n",
    "    datasets: List[Tuple[DataFrame, Series]], model: Pipeline, config\n",
    ") -> List[float]:\n",
    "    performances: List[float] = []\n",
    "    for X, y in datasets:\n",
    "        model.set_params(**config)\n",
    "        performance: float = evaluate_model_performance(model=model, X=X, y=y)\n",
    "        performances.append(performance)\n",
    "    return performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_configuration_accross_datasets(\n",
    "    config_space,\n",
    "    datasets: List[Tuple[DataFrame, Series]],\n",
    "    model: Pipeline,\n",
    "    summary_func,\n",
    "):\n",
    "    best_config = None\n",
    "    best_summary_score = float(\"0\")\n",
    "\n",
    "    for config in config_space:\n",
    "        performances = experiment(datasets=datasets, model=model, config=config)\n",
    "        summary_score = summary_func(performances)\n",
    "\n",
    "        if summary_score > best_summary_score:\n",
    "            best_summary_score = summary_score\n",
    "            best_config = config\n",
    "\n",
    "    return best_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_market_dataset_id = (\n",
    "    43308  # https://www.openml.org/search?type=data&id=43308&sort=runs&status=active\n",
    ")\n",
    "liver_disorders_dataset_id = (\n",
    "    8  # https://www.openml.org/search?type=data&id=8&sort=runs&status=active\n",
    ")\n",
    "diabetes_dataset_id = (\n",
    "    44223  # https://www.openml.org/search?type=data&id=44223&sort=runs&status=active\n",
    ")\n",
    "\n",
    "lisbona_house_prices_dataset_id = (\n",
    "    43660  # https://www.openml.org/search?type=data&id=43660&sort=runs&status=active\n",
    ")\n",
    "\n",
    "\n",
    "fish_market_dataset: DataFrame = load_dataset_from_id(id=fish_market_dataset_id)\n",
    "fish_market_regression_class = \"Weight\"\n",
    "\n",
    "liver_disorders_dataset: DataFrame = load_dataset_from_id(id=liver_disorders_dataset_id)\n",
    "liver_disorders_regression_class = \"drinks\"\n",
    "diabetes_dataset: DataFrame = load_dataset_from_id(id=diabetes_dataset_id)\n",
    "diabetes_regression_class = \"class\"\n",
    "\n",
    "lisbona_house_prices_dataset: DataFrame = load_dataset_from_id(\n",
    "    id=lisbona_house_prices_dataset_id\n",
    ")\n",
    "lisbona_house_prices_regression_class = \"Price\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_train_fish_market,\n",
    "    X_test_fish_market,\n",
    "    y_train_fish_market,\n",
    "    y_test_fish_market,\n",
    ") = split_dataset(data=fish_market_dataset, class_=fish_market_regression_class)\n",
    "\n",
    "(\n",
    "    X_train_liver_disorders,\n",
    "    X_test_liver_disorders,\n",
    "    y_train_liver_disorders,\n",
    "    y_test_liver_disorders,\n",
    ") = split_dataset(data=liver_disorders_dataset, class_=liver_disorders_regression_class)\n",
    "\n",
    "X_train_diabetes, X_test_diabetes, y_train_diabetes, y_test_diabetes = split_dataset(\n",
    "    diabetes_dataset, diabetes_regression_class\n",
    ")\n",
    "\n",
    "(\n",
    "    X_train_lisbona_house_prices,\n",
    "    X_test_lisbona_house_prices,\n",
    "    y_train_lisbona_house_prices,\n",
    "    y_test_lisbona_house_prices,\n",
    ") = split_dataset(lisbona_house_prices_dataset, lisbona_house_prices_regression_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets() -> List[Tuple[DataFrame, Series]]:\n",
    "    return [\n",
    "        (X_train_fish_market, y_train_fish_market),\n",
    "        (X_train_liver_disorders, y_train_liver_disorders),\n",
    "        (X_train_diabetes, y_train_diabetes),\n",
    "        (X_train_lisbona_house_prices, y_train_lisbona_house_prices),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create generic column transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decision_tree_pipeline() -> Pipeline:\n",
    "    decision_tree = DecisionTreeRegressor()\n",
    "    col_trans: ColumnTransformer = get_column_transformer()\n",
    "    decision_tree_pipeline = Pipeline(\n",
    "        steps=[(\"column_transformer\", col_trans), (\"model\", decision_tree)]\n",
    "    )\n",
    "    return decision_tree_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameter_grid_decision_tree():\n",
    "    # parameters space\n",
    "    ccp_alpha_values = [i * 0.1 for i in range(11)]\n",
    "    max_depth_values = range(1, 31, 1)\n",
    "    min_samples_split_values = range(2, 61, 1)\n",
    "    min_samples_leaf_values = range(1, 61, 1)\n",
    "\n",
    "    all_combinations = list(\n",
    "        itertools.product(\n",
    "            ccp_alpha_values,\n",
    "            max_depth_values,\n",
    "            min_samples_split_values,\n",
    "            min_samples_leaf_values,\n",
    "        )\n",
    "    )\n",
    "    selected_combinations: List[Tuple[float, int, int, int]] = random.sample(\n",
    "        all_combinations, 100\n",
    "    )\n",
    "    parameter_names = [\n",
    "        \"model__ccp_alpha\",\n",
    "        \"model__max_depth\",\n",
    "        \"model__min_samples_split\",\n",
    "        \"model__min_samples_leaf\",\n",
    "    ]\n",
    "\n",
    "    parameters_grid = [\n",
    "        dict(zip(parameter_names, combination)) for combination in selected_combinations\n",
    "    ]\n",
    "    return parameters_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets: List[Tuple[DataFrame, Series]] = get_datasets()\n",
    "decison_tree_pipeline: Pipeline = get_decision_tree_pipeline()\n",
    "parameters_grid_decision_tree = get_parameter_grid_decision_tree()\n",
    "\n",
    "optimal_config_decision_tree = find_optimal_configuration_accross_datasets(\n",
    "    config_space=parameters_grid_decision_tree,\n",
    "    datasets=datasets,\n",
    "    model=decison_tree_pipeline,\n",
    "    summary_func=np.mean,  # Or np.median for a more robust approach\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimal_config_decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_pipeline_on_datasets(\n",
    "    get_decision_tree_pipeline(), optimal_config_decision_tree, datasets\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elasticnet_pipeline() -> Pipeline:\n",
    "    elastic_net = ElasticNet(max_iter=10000)\n",
    "    col_trans: ColumnTransformer = get_column_transformer()\n",
    "    decision_tree_pipeline = Pipeline(\n",
    "        steps=[(\"column_transformer\", col_trans), (\"model\", elastic_net)]\n",
    "    )\n",
    "    return decision_tree_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameter_grid_for_elasticnet():\n",
    "    # parameters space\n",
    "    alpha = [i * 0.05 for i in range(21)]\n",
    "    l1_ratio = [i * 0.05 for i in range(21)]\n",
    "    all_combinations = list(\n",
    "        itertools.product(\n",
    "            alpha,\n",
    "            l1_ratio,\n",
    "        )\n",
    "    )\n",
    "    selected_combinations: List[Tuple[float, int, int, int]] = random.sample(\n",
    "        all_combinations, 100\n",
    "    )\n",
    "    parameter_names = [\n",
    "        \"model__alpha\",\n",
    "        \"model__l1_ratio\",\n",
    "    ]\n",
    "\n",
    "    parameters_grid_elasticnet = [\n",
    "        dict(zip(parameter_names, combination)) for combination in selected_combinations\n",
    "    ]\n",
    "    return parameters_grid_elasticnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets: List[Tuple[DataFrame, Series]] = get_datasets()\n",
    "elastic_net_pipeline: Pipeline = get_elasticnet_pipeline()\n",
    "parameters_grid_elasticnet = get_parameter_grid_for_elasticnet()\n",
    "optimal_config_elasticnet = find_optimal_configuration_accross_datasets(\n",
    "    config_space=parameters_grid_elasticnet,\n",
    "    datasets=datasets,\n",
    "    model=elastic_net_pipeline,\n",
    "    summary_func=np.mean,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimal_config_elasticnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_pipeline_on_datasets(\n",
    "    get_elasticnet_pipeline(), optimal_config_elasticnet, datasets\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_forest_pipeline():\n",
    "    random_forest = RandomForestRegressor()\n",
    "    col_trans: ColumnTransformer = get_column_transformer()\n",
    "    random_forest_pipeline = Pipeline(\n",
    "        steps=[(\"column_transformer\", col_trans), (\"model\", random_forest)]\n",
    "    )\n",
    "    return random_forest_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameter_grid_for_random_forest():\n",
    "    # parameters space\n",
    "    max_depth_values = range(1, 31, 1)\n",
    "    min_samples_split_values = range(2, 61, 1)\n",
    "    min_samples_leaf_values = range(1, 61, 1)\n",
    "    n_estimators_values = range(1, 200, 1)\n",
    "\n",
    "    all_combinations = list(\n",
    "        itertools.product(\n",
    "            max_depth_values,\n",
    "            min_samples_split_values,\n",
    "            min_samples_leaf_values,\n",
    "            n_estimators_values,\n",
    "        )\n",
    "    )\n",
    "    selected_combinations: List[Tuple[float, int, int, int]] = random.sample(\n",
    "        all_combinations, 100\n",
    "    )\n",
    "    parameter_names = [\n",
    "        \"model__max_depth\",\n",
    "        \"model__min_samples_split\",\n",
    "        \"model__min_samples_leaf\",\n",
    "        \"model__n_estimators\",\n",
    "    ]\n",
    "\n",
    "    parameters_grid_random_forest = [\n",
    "        dict(zip(parameter_names, combination)) for combination in selected_combinations\n",
    "    ]\n",
    "    return parameters_grid_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets: List[Tuple[DataFrame, Series]] = get_datasets()\n",
    "random_forest_pipeline: Pipeline = get_random_forest_pipeline()\n",
    "parameters_grid_random_forest = get_parameter_grid_for_random_forest()\n",
    "\n",
    "optimal_config_random_forest = find_optimal_configuration_accross_datasets(\n",
    "    config_space=parameters_grid_random_forest,\n",
    "    datasets=datasets,\n",
    "    model=random_forest_pipeline,\n",
    "    summary_func=np.mean,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimal_config_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_pipeline_on_datasets(\n",
    "    get_random_forest_pipeline(), optimal_config_random_forest, datasets\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes - decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_params = {\n",
    "    \"model__ccp_alpha\": Real(0.11, 1.21, prior=\"log-uniform\"),\n",
    "    \"model__max_depth\": Integer(1, 31, prior=\"log-uniform\"),\n",
    "    \"model__min_samples_split\": Integer(2, 61, prior=\"log-uniform\"),\n",
    "    \"model__min_samples_leaf\": Integer(2, 61, prior=\"log-uniform\"),\n",
    "}\n",
    "\n",
    "decision_tree_params = {\n",
    "    \"model__ccp_alpha\": Real(0.11, 1.21, prior=\"log-uniform\"),\n",
    "    \"model__max_depth\": Integer(1, 31, prior=\"log-uniform\"),\n",
    "    \"model__min_samples_split\": Integer(2, 61, prior=\"log-uniform\"),\n",
    "    \"model__min_samples_leaf\": Integer(2, 61, prior=\"log-uniform\"),\n",
    "}\n",
    "\n",
    "out = get_bayes_best_configuration(\n",
    "    get_decision_tree_pipeline(),\n",
    "    [\n",
    "        (decision_tree_params, 30),\n",
    "        (decision_tree_params, 30),\n",
    "        (decision_tree_params, 30),\n",
    "        (decision_tree_params, 30),\n",
    "    ],\n",
    "    X_train_fish_market,\n",
    "    y_train_fish_market,\n",
    "    X_test_fish_market,\n",
    "    y_test_fish_market,\n",
    ")\n",
    "\n",
    "print(out[0])\n",
    "print(out[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
